START ma 6.2.2023 10.56.44 +0200
Namespace(model='models/finbert-large-deepl', data='data/test_fi_deepl.jsonl', tokenizer='TurkuNLP/bert-base-finnish-cased-v1', filename='test3.tsv', new_test=True, threshold=0.6499999999999999)
                                                text  ...              labels
0  Persujen mamu-puputus kyllästyttää  mutta mamu...  ...  [0, 0, 0, 0, 0, 1]
1  Suvakit ja hyysärit haluaa saada lapset omaan ...  ...  [0, 0, 0, 0, 0, 1]
2  VIELÄ YKSI ASIA! NÄMÄ EI OLE HENKILÖVAALIT,VAA...  ...  [0, 0, 0, 0, 0, 0]
3  Halosen aikana on lapsiin ja naisiin kohdistun...  ...  [0, 0, 0, 0, 0, 1]
4  Byää! Byää! Jos tulee vammoja, byää! Saatanan ...  ...  [0, 0, 0, 0, 0, 1]

[5 rows x 3 columns]
Dataset({
    features: ['text', 'id', 'labels'],
    num_rows: 2252
})
tensor([[1.1840e-01, 5.8340e-02, 1.4804e-01, 3.0689e-03, 5.7892e-03, 9.3099e-01],
        [8.5944e-02, 3.9587e-02, 1.2726e-01, 3.2833e-03, 1.2636e-02, 9.2524e-01],
        [1.3314e-03, 3.4000e-03, 7.9556e-03, 1.6218e-04, 1.7250e-03, 6.3318e-02],
        [4.3667e-02, 1.0461e-01, 1.8257e-01, 5.1093e-03, 8.1963e-03, 9.8091e-01],
        [9.9302e-01, 9.9851e-01, 9.9841e-01, 7.2457e-01, 5.2963e-02, 9.9922e-01],
        [3.0064e-04, 1.1481e-03, 2.7582e-03, 6.5535e-05, 4.8457e-04, 2.0657e-02],
        [1.1050e-02, 2.5606e-02, 1.0061e-01, 1.0591e-03, 4.6801e-03, 5.2831e-01],
        [3.4559e-03, 5.7862e-02, 9.5298e-01, 1.1666e-02, 4.2714e-03, 9.7839e-01],
        [8.4953e-03, 2.8285e-02, 1.0968e-01, 9.5429e-04, 3.1840e-03, 4.8982e-01],
        [7.8740e-04, 2.4626e-03, 5.4028e-03, 1.1414e-04, 1.1117e-03, 4.0459e-02]])
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 ...
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]]
[[0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]]
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]]
                       precision    recall  f1-score   support

label_identity_attack       1.00      0.29      0.45       131
         label_insult       1.00      0.43      0.60       141
        label_obscene       1.00      0.78      0.87       170
label_severe_toxicity       1.00      0.24      0.39        25
         label_threat       1.00      0.23      0.37        40
       label_toxicity       1.00      0.74      0.85       158

            micro avg       1.00      0.55      0.71       665
            macro avg       1.00      0.45      0.59       665
         weighted avg       1.00      0.55      0.68       665
          samples avg       0.16      0.16      0.16       665

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'eval_accuracy': 0.8658969804618117,
 'eval_f1': 0.7062256809338522,
 'eval_f1_macro': 0.5888649212266751,
 'eval_hamming loss': 0.02235050325636471,
 'eval_loss': 1.3107070922851562,
 'eval_macro_roc_auc': 0.7253897805585215,
 'eval_micro_roc_auc': 0.7729323308270677,
 'eval_precision': 1.0,
 'eval_probs_roc_auc': 0.7003364227113725,
 'eval_recall': 0.5458646616541354,
 'eval_runtime': 76.0415,
 'eval_samples_per_second': 29.615,
 'eval_steps_per_second': 3.709}
tensor([[1.1840e-01, 5.8340e-02, 1.4804e-01, 3.0689e-03, 5.7892e-03, 9.3099e-01],
        [8.5944e-02, 3.9587e-02, 1.2726e-01, 3.2833e-03, 1.2636e-02, 9.2524e-01],
        [1.3314e-03, 3.4000e-03, 7.9556e-03, 1.6218e-04, 1.7250e-03, 6.3318e-02],
        [4.3667e-02, 1.0461e-01, 1.8257e-01, 5.1093e-03, 8.1963e-03, 9.8091e-01],
        [9.9302e-01, 9.9851e-01, 9.9841e-01, 7.2457e-01, 5.2963e-02, 9.9922e-01],
        [3.0064e-04, 1.1481e-03, 2.7582e-03, 6.5535e-05, 4.8457e-04, 2.0657e-02],
        [1.1050e-02, 2.5606e-02, 1.0061e-01, 1.0591e-03, 4.6801e-03, 5.2831e-01],
        [3.4559e-03, 5.7862e-02, 9.5298e-01, 1.1666e-02, 4.2714e-03, 9.7839e-01],
        [8.4953e-03, 2.8285e-02, 1.0968e-01, 9.5429e-04, 3.1840e-03, 4.8982e-01],
        [7.8740e-04, 2.4626e-03, 5.4028e-03, 1.1414e-04, 1.1117e-03, 4.0459e-02]])
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 ...
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]]
[[0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]]
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]]
                       precision    recall  f1-score   support

label_identity_attack       1.00      0.29      0.45       131
         label_insult       1.00      0.43      0.60       141
        label_obscene       1.00      0.78      0.87       170
label_severe_toxicity       1.00      0.24      0.39        25
         label_threat       1.00      0.23      0.37        40
       label_toxicity       1.00      0.74      0.85       158

            micro avg       1.00      0.55      0.71       665
            macro avg       1.00      0.45      0.59       665
         weighted avg       1.00      0.55      0.68       665
          samples avg       0.16      0.16      0.16       665

[[-2.0077057  -2.781364   -1.7500454  -5.7833786  -5.1459584   2.6019304 ]
 [-2.3641934  -3.1888514  -1.9253647  -5.715632   -4.3584876   2.5157344 ]
 [-6.620192   -5.6805673  -4.825888   -8.726649   -6.360818   -2.6941755 ]
 [-3.0865114  -2.147026   -1.4990041  -5.271564   -4.7958407   3.9392066 ]
 [ 4.958264    6.510385    6.4413867   0.9672206  -2.8837404   7.1610117 ]
 [-8.109295   -6.7684617  -5.8904324  -9.632868   -7.631772   -3.8588173 ]
 [-4.4942093  -3.638971   -2.1904821  -6.8492837  -5.35975     0.11336099]
 [-5.6642     -2.790094    3.0090714  -4.4393096  -5.451525    3.8125749 ]
 [-4.7597065  -3.5367484  -2.0940561  -6.953586   -5.74644    -0.04072533]
 [-7.1459813  -6.0040603  -5.2154245  -9.07795    -6.8007326  -3.1661634 ]]
tensor([[1.1840e-01, 5.8340e-02, 1.4804e-01, 3.0689e-03, 5.7892e-03, 9.3099e-01],
        [8.5944e-02, 3.9587e-02, 1.2726e-01, 3.2833e-03, 1.2636e-02, 9.2524e-01],
        [1.3314e-03, 3.4000e-03, 7.9556e-03, 1.6218e-04, 1.7250e-03, 6.3318e-02],
        [4.3667e-02, 1.0461e-01, 1.8257e-01, 5.1093e-03, 8.1963e-03, 9.8091e-01],
        [9.9302e-01, 9.9851e-01, 9.9841e-01, 7.2457e-01, 5.2963e-02, 9.9922e-01],
        [3.0064e-04, 1.1481e-03, 2.7582e-03, 6.5535e-05, 4.8457e-04, 2.0657e-02],
        [1.1050e-02, 2.5606e-02, 1.0061e-01, 1.0591e-03, 4.6801e-03, 5.2831e-01],
        [3.4559e-03, 5.7862e-02, 9.5298e-01, 1.1666e-02, 4.2714e-03, 9.7839e-01],
        [8.4953e-03, 2.8285e-02, 1.0968e-01, 9.5429e-04, 3.1840e-03, 4.8982e-01],
        [7.8740e-04, 2.4626e-03, 5.4028e-03, 1.1414e-04, 1.1117e-03, 4.0459e-02]])
END: ma 6.2.2023 11.00.42 +0200
