START ma 6.2.2023 15.26.23 +0200
Namespace(model='models/good_finbert_based_model', data='data/test_fi_deepl.jsonl', tokenizer='TurkuNLP/bert-base-finnish-cased-v1', filename='test4.tsv', new_test=True, threshold=0.6499999999999999)
                                                   text  ...                 labels
0     Persujen mamu-puputus kyllästyttää  mutta mamu...  ...  [0, 0, 0, 0, 0, 1, 0]
1     Suvakit ja hyysärit haluaa saada lapset omaan ...  ...  [0, 0, 0, 0, 0, 1, 0]
2     VIELÄ YKSI ASIA! NÄMÄ EI OLE HENKILÖVAALIT,VAA...  ...  [0, 0, 0, 0, 0, 0, 1]
3     Halosen aikana on lapsiin ja naisiin kohdistun...  ...  [0, 0, 0, 0, 0, 1, 0]
4     Byää! Byää! Jos tulee vammoja, byää! Saatanan ...  ...  [0, 0, 0, 0, 0, 1, 0]
...                                                 ...  ...                    ...
2255  Haista sinä vittu. Ryssähän se tänne on koko a...  ...  [0, 0, 0, 0, 0, 0, 1]
2256  Äsen Ylen uutisissa: Lapin käräjäoikeus on hyl...  ...  [0, 0, 0, 0, 0, 0, 1]
2257  mä en jaksa enää sitä haukkumista,perkele kun ...  ...  [0, 0, 0, 0, 0, 0, 1]
2258  Ei ainakaan Chrome tyrkytä. Se aina kysyy että...  ...  [0, 0, 0, 0, 0, 0, 1]
2259  Eihän noi ole ku paskapentuja 1 kaljan jälkeen...  ...  [0, 0, 0, 0, 1, 0, 0]

[2260 rows x 3 columns]
Dataset({
    features: ['text', 'id', 'labels'],
    num_rows: 2260
})
before change
[[0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 1. 0.]]
tensor([[3.3179e-01, 5.7473e-02, 8.8422e-02, 3.9735e-03, 3.0139e-03, 8.0527e-01,
         4.6743e-02],
        [9.9903e-02, 2.0122e-02, 1.0501e-02, 1.5696e-03, 2.6113e-03, 4.3851e-01,
         2.3515e-01],
        [2.9656e-03, 6.9872e-03, 1.2759e-02, 1.1924e-03, 1.8767e-03, 1.5613e-01,
         6.1321e-01],
        [1.9189e-01, 9.2663e-02, 2.0223e-02, 2.1679e-03, 2.7403e-03, 7.2968e-01,
         5.9018e-02],
        [7.7994e-01, 9.3901e-01, 8.6069e-01, 1.1637e-01, 1.4544e-02, 9.8708e-01,
         1.3221e-03],
        [4.9249e-03, 1.0395e-02, 4.9005e-03, 3.3124e-04, 4.9234e-04, 9.0962e-02,
         7.0388e-01],
        [8.1537e-03, 6.0281e-02, 3.7090e-02, 3.3116e-03, 1.2209e-02, 7.1297e-01,
         7.2226e-02],
        [4.5061e-03, 4.0090e-02, 3.6305e-01, 2.0898e-03, 1.2395e-03, 7.0174e-01,
         5.4594e-02],
        [3.2188e-03, 3.4176e-02, 1.8139e-01, 2.6115e-03, 2.2924e-03, 6.3795e-01,
         1.0367e-01],
        [1.3110e-02, 3.8686e-02, 4.7749e-03, 6.2443e-04, 8.5153e-04, 2.7914e-01,
         4.1353e-01]])
[[0. 0. 0. ... 0. 1. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 1. 1. ... 0. 1. 0.]
 [0. 0. 0. ... 0. 0. 1.]
 [0. 0. 0. ... 1. 0. 0.]]
[array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1])]
[array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1])]
[array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.])]
                       precision    recall  f1-score   support

label_identity_attack       0.27      0.49      0.35       131
         label_insult       0.12      0.42      0.18       145
        label_obscene       0.13      0.49      0.21       170
label_severe_toxicity       0.07      0.24      0.11        25
         label_threat       0.28      0.45      0.34        40
       label_toxicity       0.08      0.63      0.14       158

            micro avg       0.12      0.49      0.19       669
            macro avg       0.16      0.45      0.22       669
         weighted avg       0.15      0.49      0.22       669
          samples avg       0.15      0.15      0.15       669

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'eval_accuracy': 0.3668141592920354,
 'eval_f1': 0.19144013880855984,
 'eval_f1_macro': 0.22286744025070857,
 'eval_hamming loss': 0.20619469026548673,
 'eval_loss': 1.118625283241272,
 'eval_macro_roc_auc': 0.6290756719530021,
 'eval_micro_roc_auc': 0.6520463228595192,
 'eval_precision': 0.11868053065614916,
 'eval_probs_roc_auc': 1.0,
 'eval_recall': 0.4947683109118087,
 'eval_runtime': 27.2682,
 'eval_samples_per_second': 82.881,
 'eval_steps_per_second': 10.378}
before change
[[0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 1. 0.]]
tensor([[3.3179e-01, 5.7473e-02, 8.8422e-02, 3.9735e-03, 3.0139e-03, 8.0527e-01,
         4.6743e-02],
        [9.9903e-02, 2.0122e-02, 1.0501e-02, 1.5696e-03, 2.6113e-03, 4.3851e-01,
         2.3515e-01],
        [2.9656e-03, 6.9872e-03, 1.2759e-02, 1.1924e-03, 1.8767e-03, 1.5613e-01,
         6.1321e-01],
        [1.9189e-01, 9.2663e-02, 2.0223e-02, 2.1679e-03, 2.7403e-03, 7.2968e-01,
         5.9018e-02],
        [7.7994e-01, 9.3901e-01, 8.6069e-01, 1.1637e-01, 1.4544e-02, 9.8708e-01,
         1.3221e-03],
        [4.9249e-03, 1.0395e-02, 4.9005e-03, 3.3124e-04, 4.9234e-04, 9.0962e-02,
         7.0388e-01],
        [8.1537e-03, 6.0281e-02, 3.7090e-02, 3.3116e-03, 1.2209e-02, 7.1297e-01,
         7.2226e-02],
        [4.5061e-03, 4.0090e-02, 3.6305e-01, 2.0898e-03, 1.2395e-03, 7.0174e-01,
         5.4594e-02],
        [3.2188e-03, 3.4176e-02, 1.8139e-01, 2.6115e-03, 2.2924e-03, 6.3795e-01,
         1.0367e-01],
        [1.3110e-02, 3.8686e-02, 4.7749e-03, 6.2443e-04, 8.5153e-04, 2.7914e-01,
         4.1353e-01]])
[[0. 0. 0. ... 0. 1. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 1. 1. ... 0. 1. 0.]
 [0. 0. 0. ... 0. 0. 1.]
 [0. 0. 0. ... 1. 0. 0.]]
[array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1])]
[array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1])]
[array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.])]
                       precision    recall  f1-score   support

label_identity_attack       0.27      0.49      0.35       131
         label_insult       0.12      0.42      0.18       145
        label_obscene       0.13      0.49      0.21       170
label_severe_toxicity       0.07      0.24      0.11        25
         label_threat       0.28      0.45      0.34        40
       label_toxicity       0.08      0.63      0.14       158

            micro avg       0.12      0.49      0.19       669
            macro avg       0.16      0.45      0.22       669
         weighted avg       0.15      0.49      0.22       669
          samples avg       0.15      0.15      0.15       669

[[-0.7001025  -2.7972488  -2.3330586  -5.5241294  -5.801499    1.4195578
  -3.0152137 ]
 [-2.1982987  -3.8856387  -4.5456915  -6.4553475  -5.9452953  -0.24720658
  -1.1794487 ]
 [-5.817723   -4.956667   -4.348669   -6.730557   -6.276357   -1.6872939
   0.46082985]
 [-1.4377443  -2.2815418  -3.8805296  -6.131844   -5.8969326   0.99298227
  -2.7690744 ]
 [ 1.2653177   2.7340662   1.8210615  -2.0272896  -4.215947    4.336047
  -6.6271753 ]
 [-5.308517   -4.55602    -5.3135114  -8.0123415  -7.6158395  -2.301942
   0.86586154]
 [-4.8011003  -2.7465634  -3.2566037  -5.7069917  -4.393291    0.90983987
  -2.5529926 ]
 [-5.3978086  -3.1756997  -0.5621619  -6.1686063  -6.6918097   0.8555879
  -2.8517    ]
 [-5.735529   -3.3414493  -1.5069536  -5.94522    -6.0758753   0.5664735
  -2.1570816 ]
 [-4.3211937  -3.2128117  -5.3395886  -7.3780518  -7.0676274  -0.94874907
  -0.34937426]]
END: ma 6.2.2023 15.28.07 +0200
