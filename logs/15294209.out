START ma 6.2.2023 11.41.01 +0200
Namespace(model='models/finbert-large-deepl', data='data/test_fi_deepl.jsonl', tokenizer='TurkuNLP/bert-base-finnish-cased-v1', filename='test2.tsv', new_test=True, threshold=0.5)
                                                text  ...              labels
0  Persujen mamu-puputus kyllästyttää  mutta mamu...  ...  [0, 0, 0, 0, 0, 1]
1  Suvakit ja hyysärit haluaa saada lapset omaan ...  ...  [0, 0, 0, 0, 0, 1]
2  VIELÄ YKSI ASIA! NÄMÄ EI OLE HENKILÖVAALIT,VAA...  ...  [0, 0, 0, 0, 0, 0]
3  Halosen aikana on lapsiin ja naisiin kohdistun...  ...  [0, 0, 0, 0, 0, 1]
4  Byää! Byää! Jos tulee vammoja, byää! Saatanan ...  ...  [0, 0, 0, 0, 0, 1]

[5 rows x 3 columns]
Dataset({
    features: ['text', 'id', 'labels'],
    num_rows: 2252
})
before change
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [1. 1. 1. 1. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]]
tensor([[1.1840e-01, 5.8340e-02, 1.4804e-01, 3.0689e-03, 5.7892e-03, 9.3099e-01],
        [8.5944e-02, 3.9587e-02, 1.2726e-01, 3.2833e-03, 1.2636e-02, 9.2524e-01],
        [1.3314e-03, 3.4000e-03, 7.9556e-03, 1.6218e-04, 1.7250e-03, 6.3318e-02],
        [4.3667e-02, 1.0461e-01, 1.8257e-01, 5.1093e-03, 8.1963e-03, 9.8091e-01],
        [9.9302e-01, 9.9851e-01, 9.9841e-01, 7.2457e-01, 5.2963e-02, 9.9922e-01],
        [3.0064e-04, 1.1481e-03, 2.7582e-03, 6.5535e-05, 4.8457e-04, 2.0657e-02],
        [1.1050e-02, 2.5606e-02, 1.0061e-01, 1.0591e-03, 4.6801e-03, 5.2831e-01],
        [3.4559e-03, 5.7862e-02, 9.5298e-01, 1.1666e-02, 4.2714e-03, 9.7839e-01],
        [8.4953e-03, 2.8285e-02, 1.0968e-01, 9.5429e-04, 3.1840e-03, 4.8982e-01],
        [7.8740e-04, 2.4626e-03, 5.4028e-03, 1.1414e-04, 1.1117e-03, 4.0459e-02]])
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 ...
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]]
tensor([[1.1840e-01, 5.8340e-02, 1.4804e-01, 3.0689e-03, 5.7892e-03, 9.3099e-01],
        [8.5944e-02, 3.9587e-02, 1.2726e-01, 3.2833e-03, 1.2636e-02, 9.2524e-01],
        [1.3314e-03, 3.4000e-03, 7.9556e-03, 1.6218e-04, 1.7250e-03, 6.3318e-02],
        [4.3667e-02, 1.0461e-01, 1.8257e-01, 5.1093e-03, 8.1963e-03, 9.8091e-01],
        [9.9302e-01, 9.9851e-01, 9.9841e-01, 7.2457e-01, 5.2963e-02, 9.9922e-01],
        [3.0064e-04, 1.1481e-03, 2.7582e-03, 6.5535e-05, 4.8457e-04, 2.0657e-02],
        [1.1050e-02, 2.5606e-02, 1.0061e-01, 1.0591e-03, 4.6801e-03, 5.2831e-01],
        [3.4559e-03, 5.7862e-02, 9.5298e-01, 1.1666e-02, 4.2714e-03, 9.7839e-01],
        [8.4953e-03, 2.8285e-02, 1.0968e-01, 9.5429e-04, 3.1840e-03, 4.8982e-01],
        [7.8740e-04, 2.4626e-03, 5.4028e-03, 1.1414e-04, 1.1117e-03, 4.0459e-02],
        [2.3153e-04, 7.6717e-04, 1.8308e-03, 6.4507e-05, 4.7652e-04, 1.2835e-02],
        [7.5299e-04, 2.2751e-03, 5.1159e-03, 1.1101e-04, 1.1013e-03, 3.8370e-02],
        [1.2145e-02, 1.0133e-01, 4.3918e-01, 4.7401e-03, 5.8265e-03, 9.6724e-01],
        [5.2549e-02, 9.9673e-01, 9.9422e-01, 5.4483e-02, 1.3416e-02, 9.9800e-01],
        [1.2601e-02, 1.2079e-01, 4.1746e-01, 5.2426e-03, 6.7586e-03, 9.7791e-01],
        [1.6833e-04, 4.7275e-04, 1.1108e-03, 7.4856e-05, 3.5607e-04, 7.4998e-03],
        [1.7595e-02, 5.4628e-02, 2.2218e-01, 2.6679e-03, 7.1091e-03, 8.8283e-01],
        [1.6769e-02, 5.5754e-02, 1.8045e-01, 3.0243e-03, 1.0789e-02, 9.4087e-01],
        [2.3110e-04, 7.6603e-04, 1.8333e-03, 6.4573e-05, 4.7791e-04, 1.2838e-02],
        [3.9925e-01, 6.5319e-01, 9.6449e-01, 1.8230e-02, 4.1518e-03, 9.9205e-01],
        [1.9103e-02, 2.8545e-02, 1.0896e-01, 1.3445e-03, 5.1196e-03, 6.1394e-01],
        [1.6990e-02, 6.3727e-02, 4.4615e-01, 8.4985e-03, 8.8691e-03, 9.8658e-01],
        [3.6052e-03, 7.8018e-03, 2.0645e-02, 3.5055e-04, 4.0958e-03, 1.8517e-01],
        [1.0782e-02, 2.4858e-02, 7.4568e-02, 8.6006e-04, 3.6202e-03, 4.7710e-01],
        [1.4044e-02, 5.9392e-02, 1.2804e-01, 1.2697e-03, 3.8775e-03, 7.3303e-01],
        [4.8016e-03, 1.3546e-02, 3.4415e-02, 4.4217e-04, 2.3949e-03, 2.3065e-01],
        [1.8502e-02, 8.4011e-02, 2.1282e-01, 3.0414e-03, 8.3536e-03, 9.4078e-01],
        [3.7046e-03, 4.9031e-01, 5.9418e-01, 2.9704e-03, 2.3252e-03, 9.7833e-01],
        [8.6604e-03, 5.4315e-02, 1.0441e-01, 7.5629e-04, 2.8981e-03, 6.5202e-01],
        [8.2812e-02, 7.9361e-01, 9.8650e-01, 2.1072e-02, 4.2896e-03, 9.9417e-01]])
[[0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]]
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]]
                       precision    recall  f1-score   support

label_identity_attack       1.00      0.32      0.49       131
         label_insult       1.00      0.48      0.64       141
        label_obscene       1.00      0.83      0.91       170
label_severe_toxicity       1.00      0.28      0.44        25
         label_threat       1.00      0.28      0.43        40
       label_toxicity       1.00      0.78      0.88       158

            micro avg       1.00      0.59      0.74       665
            macro avg       1.00      0.49      0.63       665
         weighted avg       1.00      0.59      0.71       665
          samples avg       0.17      0.17      0.17       665

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'eval_accuracy': 0.8783303730017762,
 'eval_f1': 0.740530303030303,
 'eval_f1_macro': 0.6301416171052614,
 'eval_hamming loss': 0.020278271166370633,
 'eval_loss': 1.3107070922851562,
 'eval_macro_roc_auc': 0.7465567307792957,
 'eval_micro_roc_auc': 0.793984962406015,
 'eval_precision': 1.0,
 'eval_probs_roc_auc': 0.7003364227113725,
 'eval_recall': 0.58796992481203,
 'eval_runtime': 75.9784,
 'eval_samples_per_second': 29.64,
 'eval_steps_per_second': 3.712}
before change
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [1. 1. 1. 1. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]]
tensor([[1.1840e-01, 5.8340e-02, 1.4804e-01, 3.0689e-03, 5.7892e-03, 9.3099e-01],
        [8.5944e-02, 3.9587e-02, 1.2726e-01, 3.2833e-03, 1.2636e-02, 9.2524e-01],
        [1.3314e-03, 3.4000e-03, 7.9556e-03, 1.6218e-04, 1.7250e-03, 6.3318e-02],
        [4.3667e-02, 1.0461e-01, 1.8257e-01, 5.1093e-03, 8.1963e-03, 9.8091e-01],
        [9.9302e-01, 9.9851e-01, 9.9841e-01, 7.2457e-01, 5.2963e-02, 9.9922e-01],
        [3.0064e-04, 1.1481e-03, 2.7582e-03, 6.5535e-05, 4.8457e-04, 2.0657e-02],
        [1.1050e-02, 2.5606e-02, 1.0061e-01, 1.0591e-03, 4.6801e-03, 5.2831e-01],
        [3.4559e-03, 5.7862e-02, 9.5298e-01, 1.1666e-02, 4.2714e-03, 9.7839e-01],
        [8.4953e-03, 2.8285e-02, 1.0968e-01, 9.5429e-04, 3.1840e-03, 4.8982e-01],
        [7.8740e-04, 2.4626e-03, 5.4028e-03, 1.1414e-04, 1.1117e-03, 4.0459e-02]])
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 ...
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]]
tensor([[1.1840e-01, 5.8340e-02, 1.4804e-01, 3.0689e-03, 5.7892e-03, 9.3099e-01],
        [8.5944e-02, 3.9587e-02, 1.2726e-01, 3.2833e-03, 1.2636e-02, 9.2524e-01],
        [1.3314e-03, 3.4000e-03, 7.9556e-03, 1.6218e-04, 1.7250e-03, 6.3318e-02],
        [4.3667e-02, 1.0461e-01, 1.8257e-01, 5.1093e-03, 8.1963e-03, 9.8091e-01],
        [9.9302e-01, 9.9851e-01, 9.9841e-01, 7.2457e-01, 5.2963e-02, 9.9922e-01],
        [3.0064e-04, 1.1481e-03, 2.7582e-03, 6.5535e-05, 4.8457e-04, 2.0657e-02],
        [1.1050e-02, 2.5606e-02, 1.0061e-01, 1.0591e-03, 4.6801e-03, 5.2831e-01],
        [3.4559e-03, 5.7862e-02, 9.5298e-01, 1.1666e-02, 4.2714e-03, 9.7839e-01],
        [8.4953e-03, 2.8285e-02, 1.0968e-01, 9.5429e-04, 3.1840e-03, 4.8982e-01],
        [7.8740e-04, 2.4626e-03, 5.4028e-03, 1.1414e-04, 1.1117e-03, 4.0459e-02],
        [2.3153e-04, 7.6717e-04, 1.8308e-03, 6.4507e-05, 4.7652e-04, 1.2835e-02],
        [7.5299e-04, 2.2751e-03, 5.1159e-03, 1.1101e-04, 1.1013e-03, 3.8370e-02],
        [1.2145e-02, 1.0133e-01, 4.3918e-01, 4.7401e-03, 5.8265e-03, 9.6724e-01],
        [5.2549e-02, 9.9673e-01, 9.9422e-01, 5.4483e-02, 1.3416e-02, 9.9800e-01],
        [1.2601e-02, 1.2079e-01, 4.1746e-01, 5.2426e-03, 6.7586e-03, 9.7791e-01],
        [1.6833e-04, 4.7275e-04, 1.1108e-03, 7.4856e-05, 3.5607e-04, 7.4998e-03],
        [1.7595e-02, 5.4628e-02, 2.2218e-01, 2.6679e-03, 7.1091e-03, 8.8283e-01],
        [1.6769e-02, 5.5754e-02, 1.8045e-01, 3.0243e-03, 1.0789e-02, 9.4087e-01],
        [2.3110e-04, 7.6603e-04, 1.8333e-03, 6.4573e-05, 4.7791e-04, 1.2838e-02],
        [3.9925e-01, 6.5319e-01, 9.6449e-01, 1.8230e-02, 4.1518e-03, 9.9205e-01],
        [1.9103e-02, 2.8545e-02, 1.0896e-01, 1.3445e-03, 5.1196e-03, 6.1394e-01],
        [1.6990e-02, 6.3727e-02, 4.4615e-01, 8.4985e-03, 8.8691e-03, 9.8658e-01],
        [3.6052e-03, 7.8018e-03, 2.0645e-02, 3.5055e-04, 4.0958e-03, 1.8517e-01],
        [1.0782e-02, 2.4858e-02, 7.4568e-02, 8.6006e-04, 3.6202e-03, 4.7710e-01],
        [1.4044e-02, 5.9392e-02, 1.2804e-01, 1.2697e-03, 3.8775e-03, 7.3303e-01],
        [4.8016e-03, 1.3546e-02, 3.4415e-02, 4.4217e-04, 2.3949e-03, 2.3065e-01],
        [1.8502e-02, 8.4011e-02, 2.1282e-01, 3.0414e-03, 8.3536e-03, 9.4078e-01],
        [3.7046e-03, 4.9031e-01, 5.9418e-01, 2.9704e-03, 2.3252e-03, 9.7833e-01],
        [8.6604e-03, 5.4315e-02, 1.0441e-01, 7.5629e-04, 2.8981e-03, 6.5202e-01],
        [8.2812e-02, 7.9361e-01, 9.8650e-01, 2.1072e-02, 4.2896e-03, 9.9417e-01]])
[[0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]]
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]]
                       precision    recall  f1-score   support

label_identity_attack       1.00      0.32      0.49       131
         label_insult       1.00      0.48      0.64       141
        label_obscene       1.00      0.83      0.91       170
label_severe_toxicity       1.00      0.28      0.44        25
         label_threat       1.00      0.28      0.43        40
       label_toxicity       1.00      0.78      0.88       158

            micro avg       1.00      0.59      0.74       665
            macro avg       1.00      0.49      0.63       665
         weighted avg       1.00      0.59      0.71       665
          samples avg       0.17      0.17      0.17       665

[[-2.0077057  -2.781364   -1.7500454  -5.7833786  -5.1459584   2.6019304 ]
 [-2.3641934  -3.1888514  -1.9253647  -5.715632   -4.3584876   2.5157344 ]
 [-6.620192   -5.6805673  -4.825888   -8.726649   -6.360818   -2.6941755 ]
 [-3.0865114  -2.147026   -1.4990041  -5.271564   -4.7958407   3.9392066 ]
 [ 4.958264    6.510385    6.4413867   0.9672206  -2.8837404   7.1610117 ]
 [-8.109295   -6.7684617  -5.8904324  -9.632868   -7.631772   -3.8588173 ]
 [-4.4942093  -3.638971   -2.1904821  -6.8492837  -5.35975     0.11336099]
 [-5.6642     -2.790094    3.0090714  -4.4393096  -5.451525    3.8125749 ]
 [-4.7597065  -3.5367484  -2.0940561  -6.953586   -5.74644    -0.04072533]
 [-7.1459813  -6.0040603  -5.2154245  -9.07795    -6.8007326  -3.1661634 ]]
before change
[[0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [1. 1. 1. 1. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 1. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 1. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 1. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 1. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 1. 1. 1. 0. 1.]]
tensor([[1.8909e-01, 9.9718e-01, 9.9965e-01, 9.9434e-01, 4.3099e-02, 9.9970e-01],
        [1.8854e-02, 8.5522e-01, 9.9668e-01, 6.9854e-02, 1.2542e-02, 9.9747e-01],
        [9.4809e-03, 7.0119e-02, 3.9579e-01, 1.0017e-02, 2.2325e-02, 9.8795e-01],
        [4.7317e-03, 9.3155e-02, 9.8568e-01, 3.3466e-02, 7.6153e-03, 9.9163e-01],
        [3.4923e-02, 2.3868e-01, 9.3063e-01, 2.0684e-02, 5.7404e-03, 9.9336e-01],
        [1.8626e-02, 9.8906e-01, 9.9717e-01, 8.8798e-02, 1.7056e-02, 9.9817e-01],
        [1.3980e-02, 9.9246e-01, 9.4616e-01, 1.3175e-02, 4.6130e-03, 9.9554e-01],
        [3.2738e-02, 9.9610e-01, 9.9759e-01, 1.1568e-01, 1.5662e-02, 9.9858e-01],
        [4.2690e-02, 8.7360e-01, 9.0449e-01, 2.8231e-02, 3.5744e-02, 9.9629e-01],
        [1.3567e-01, 9.9489e-01, 9.9901e-01, 3.5382e-01, 1.7698e-02, 9.9942e-01],
        [5.5966e-02, 9.9696e-01, 9.9741e-01, 8.0540e-02, 8.2287e-03, 9.9824e-01],
        [1.2568e-02, 8.7127e-01, 9.9833e-01, 1.5556e-01, 1.1076e-02, 9.9847e-01],
        [1.2637e-01, 9.9783e-01, 9.9895e-01, 3.8027e-01, 2.4107e-02, 9.9951e-01],
        [3.9571e-03, 4.9309e-02, 9.8036e-01, 2.2609e-02, 6.0968e-03, 9.8483e-01],
        [2.0937e-02, 9.8949e-01, 9.9855e-01, 1.8452e-01, 1.5023e-02, 9.9900e-01],
        [5.0662e-02, 9.9805e-01, 9.9921e-01, 7.0916e-01, 2.5379e-02, 9.9955e-01],
        [5.4110e-02, 9.9644e-01, 9.8936e-01, 3.3482e-02, 9.8703e-03, 9.9770e-01],
        [1.7793e-02, 6.9525e-01, 9.9819e-01, 2.8987e-01, 6.9133e-03, 9.9846e-01],
        [7.6255e-01, 9.8469e-01, 9.8918e-01, 3.5555e-02, 8.5888e-03, 9.9569e-01],
        [3.4770e-02, 9.9332e-01, 9.9725e-01, 6.9636e-02, 1.0073e-02, 9.9808e-01],
        [1.9276e-02, 9.8206e-01, 9.9863e-01, 1.6842e-01, 2.4541e-02, 9.9894e-01],
        [1.5430e-02, 9.8305e-01, 9.9495e-01, 3.5983e-02, 6.0987e-03, 9.9692e-01],
        [1.1179e-02, 8.5600e-01, 9.9265e-01, 3.1628e-02, 5.5962e-03, 9.9523e-01],
        [1.3913e-01, 9.9716e-01, 9.9966e-01, 9.9181e-01, 3.6763e-02, 9.9967e-01],
        [1.0939e-02, 9.8927e-01, 9.9888e-01, 2.2177e-01, 1.7266e-02, 9.9908e-01],
        [8.6834e-03, 7.2247e-01, 4.9463e-01, 5.7940e-03, 8.3576e-03, 9.9058e-01],
        [2.5947e-02, 9.9521e-01, 9.9925e-01, 5.3096e-01, 2.2025e-02, 9.9944e-01],
        [2.0014e-04, 4.6704e-04, 7.5951e-04, 1.2311e-04, 2.7661e-04, 2.9103e-03],
        [2.7539e-02, 9.9659e-01, 9.9871e-01, 2.1215e-01, 1.8381e-02, 9.9918e-01],
        [2.0323e-02, 9.7582e-01, 9.9870e-01, 3.3349e-01, 1.7391e-02, 9.9935e-01],
        [2.9349e-02, 9.9792e-01, 9.9836e-01, 1.5188e-01, 1.3974e-02, 9.9896e-01],
        [2.9281e-02, 9.9631e-01, 9.9751e-01, 9.0617e-02, 9.1772e-03, 9.9827e-01],
        [9.9968e-01, 9.6862e-01, 7.5705e-01, 3.3465e-01, 4.2580e-01, 9.9538e-01],
        [2.1672e-02, 3.3768e-01, 7.8441e-02, 4.1818e-03, 1.1121e-02, 9.9084e-01],
        [2.0239e-02, 8.5227e-01, 9.9382e-01, 5.5949e-02, 8.2589e-03, 9.9647e-01],
        [6.9112e-02, 9.9785e-01, 9.9919e-01, 7.5959e-01, 1.9839e-02, 9.9953e-01],
        [3.3041e-02, 9.9377e-01, 9.9735e-01, 8.2994e-02, 1.0583e-02, 9.9821e-01],
        [1.7164e-04, 4.3079e-04, 8.8282e-04, 9.1515e-05, 3.0433e-04, 4.8031e-03],
        [3.8682e-03, 2.5259e-01, 9.9646e-01, 1.0070e-01, 7.5198e-03, 9.9679e-01],
        [6.8160e-03, 1.4539e-01, 9.8283e-01, 3.8779e-02, 1.0567e-02, 9.9310e-01],
        [4.1293e-02, 4.4386e-02, 1.8075e-01, 2.4264e-01, 9.9896e-01, 9.7609e-01],
        [7.1947e-03, 2.2807e-01, 9.9510e-01, 9.1825e-02, 8.5230e-03, 9.9692e-01],
        [2.1657e-02, 6.4473e-02, 1.1678e-01, 6.7976e-03, 6.8023e-02, 9.8311e-01],
        [4.2175e-02, 9.9574e-01, 9.9754e-01, 1.2378e-01, 1.4462e-02, 9.9855e-01],
        [1.4455e-01, 9.9793e-01, 9.9957e-01, 9.8910e-01, 1.9957e-02, 9.9964e-01],
        [1.8069e-04, 5.4300e-04, 1.3141e-03, 6.8990e-05, 3.9115e-04, 9.3639e-03],
        [9.9912e-01, 9.6484e-01, 6.4198e-01, 6.9500e-02, 2.1766e-02, 9.9252e-01],
        [8.3936e-03, 9.8420e-01, 9.9438e-01, 2.9537e-02, 4.9046e-03, 9.9540e-01],
        [1.0288e-02, 9.4832e-01, 9.9539e-01, 1.1375e-01, 2.2369e-02, 9.9807e-01],
        [6.2545e-03, 2.5661e-01, 9.9411e-01, 6.1712e-02, 1.1476e-02, 9.9615e-01]])
[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]
[[0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]]
END: ma 6.2.2023 11.44.18 +0200
