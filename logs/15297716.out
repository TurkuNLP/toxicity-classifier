START ma 6.2.2023 15.28.21 +0200
Namespace(model='models/good_finbert_based_model', data='data/test_fi_deepl.jsonl', tokenizer='TurkuNLP/bert-base-finnish-cased-v1', filename='test4.tsv', new_test=True, threshold=0.6499999999999999)
                                                   text  ...                 labels
0     Persujen mamu-puputus kyllästyttää  mutta mamu...  ...  [0, 0, 0, 0, 0, 1, 0]
1     Suvakit ja hyysärit haluaa saada lapset omaan ...  ...  [0, 0, 0, 0, 0, 1, 0]
2     VIELÄ YKSI ASIA! NÄMÄ EI OLE HENKILÖVAALIT,VAA...  ...  [0, 0, 0, 0, 0, 0, 1]
3     Halosen aikana on lapsiin ja naisiin kohdistun...  ...  [0, 0, 0, 0, 0, 1, 0]
4     Byää! Byää! Jos tulee vammoja, byää! Saatanan ...  ...  [0, 0, 0, 0, 0, 1, 0]
...                                                 ...  ...                    ...
2255  Haista sinä vittu. Ryssähän se tänne on koko a...  ...  [0, 0, 0, 0, 0, 0, 1]
2256  Äsen Ylen uutisissa: Lapin käräjäoikeus on hyl...  ...  [0, 0, 0, 0, 0, 0, 1]
2257  mä en jaksa enää sitä haukkumista,perkele kun ...  ...  [0, 0, 0, 0, 0, 0, 1]
2258  Ei ainakaan Chrome tyrkytä. Se aina kysyy että...  ...  [0, 0, 0, 0, 0, 0, 1]
2259  Eihän noi ole ku paskapentuja 1 kaljan jälkeen...  ...  [0, 0, 0, 0, 1, 0, 0]

[2260 rows x 3 columns]
Dataset({
    features: ['text', 'id', 'labels'],
    num_rows: 2260
})
before change
[[0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 1. 0.]]
tensor([[3.3179e-01, 5.7473e-02, 8.8422e-02, 3.9735e-03, 3.0139e-03, 8.0527e-01,
         4.6743e-02],
        [9.9903e-02, 2.0122e-02, 1.0501e-02, 1.5696e-03, 2.6113e-03, 4.3851e-01,
         2.3515e-01],
        [2.9656e-03, 6.9872e-03, 1.2759e-02, 1.1924e-03, 1.8767e-03, 1.5613e-01,
         6.1321e-01],
        [1.9189e-01, 9.2663e-02, 2.0223e-02, 2.1679e-03, 2.7403e-03, 7.2968e-01,
         5.9018e-02],
        [7.7994e-01, 9.3901e-01, 8.6069e-01, 1.1637e-01, 1.4544e-02, 9.8708e-01,
         1.3221e-03],
        [4.9249e-03, 1.0395e-02, 4.9005e-03, 3.3124e-04, 4.9234e-04, 9.0962e-02,
         7.0388e-01],
        [8.1537e-03, 6.0281e-02, 3.7090e-02, 3.3116e-03, 1.2209e-02, 7.1297e-01,
         7.2226e-02],
        [4.5061e-03, 4.0090e-02, 3.6305e-01, 2.0898e-03, 1.2395e-03, 7.0174e-01,
         5.4594e-02],
        [3.2188e-03, 3.4176e-02, 1.8139e-01, 2.6115e-03, 2.2924e-03, 6.3795e-01,
         1.0367e-01],
        [1.3110e-02, 3.8686e-02, 4.7749e-03, 6.2443e-04, 8.5153e-04, 2.7914e-01,
         4.1353e-01]])
[[0. 0. 0. ... 0. 1. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 1. 1. ... 0. 1. 0.]
 [0. 0. 0. ... 0. 0. 1.]
 [0. 0. 0. ... 1. 0. 0.]]
[array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1])]
[array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1])]
[array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.])]
                       precision    recall  f1-score   support

label_identity_attack       0.27      0.49      0.35       131
         label_insult       0.12      0.42      0.18       145
        label_obscene       0.13      0.49      0.21       170
label_severe_toxicity       0.07      0.24      0.11        25
         label_threat       0.28      0.45      0.34        40
       label_toxicity       0.08      0.63      0.14       158

            micro avg       0.12      0.49      0.19       669
            macro avg       0.16      0.45      0.22       669
         weighted avg       0.15      0.49      0.22       669
          samples avg       0.15      0.15      0.15       669

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'eval_accuracy': 0.3668141592920354,
 'eval_f1': 0.19144013880855984,
 'eval_f1_macro': 0.22286744025070857,
 'eval_hamming loss': 0.20619469026548673,
 'eval_loss': 1.118625283241272,
 'eval_macro_roc_auc': 0.6290756719530021,
 'eval_micro_roc_auc': 0.6520463228595192,
 'eval_precision': 0.11868053065614916,
 'eval_probs_roc_auc': 1.0,
 'eval_recall': 0.4947683109118087,
 'eval_runtime': 26.7795,
 'eval_samples_per_second': 84.393,
 'eval_steps_per_second': 10.568}
before change
[[0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 1. 0.]]
tensor([[3.3179e-01, 5.7473e-02, 8.8422e-02, 3.9735e-03, 3.0139e-03, 8.0527e-01,
         4.6743e-02],
        [9.9903e-02, 2.0122e-02, 1.0501e-02, 1.5696e-03, 2.6113e-03, 4.3851e-01,
         2.3515e-01],
        [2.9656e-03, 6.9872e-03, 1.2759e-02, 1.1924e-03, 1.8767e-03, 1.5613e-01,
         6.1321e-01],
        [1.9189e-01, 9.2663e-02, 2.0223e-02, 2.1679e-03, 2.7403e-03, 7.2968e-01,
         5.9018e-02],
        [7.7994e-01, 9.3901e-01, 8.6069e-01, 1.1637e-01, 1.4544e-02, 9.8708e-01,
         1.3221e-03],
        [4.9249e-03, 1.0395e-02, 4.9005e-03, 3.3124e-04, 4.9234e-04, 9.0962e-02,
         7.0388e-01],
        [8.1537e-03, 6.0281e-02, 3.7090e-02, 3.3116e-03, 1.2209e-02, 7.1297e-01,
         7.2226e-02],
        [4.5061e-03, 4.0090e-02, 3.6305e-01, 2.0898e-03, 1.2395e-03, 7.0174e-01,
         5.4594e-02],
        [3.2188e-03, 3.4176e-02, 1.8139e-01, 2.6115e-03, 2.2924e-03, 6.3795e-01,
         1.0367e-01],
        [1.3110e-02, 3.8686e-02, 4.7749e-03, 6.2443e-04, 8.5153e-04, 2.7914e-01,
         4.1353e-01]])
[[0. 0. 0. ... 0. 1. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 1. 1. ... 0. 1. 0.]
 [0. 0. 0. ... 0. 0. 1.]
 [0. 0. 0. ... 1. 0. 0.]]
[array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1])]
[array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 0, 1])]
[array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.])]
                       precision    recall  f1-score   support

label_identity_attack       0.27      0.49      0.35       131
         label_insult       0.12      0.42      0.18       145
        label_obscene       0.13      0.49      0.21       170
label_severe_toxicity       0.07      0.24      0.11        25
         label_threat       0.28      0.45      0.34        40
       label_toxicity       0.08      0.63      0.14       158

            micro avg       0.12      0.49      0.19       669
            macro avg       0.16      0.45      0.22       669
         weighted avg       0.15      0.49      0.22       669
          samples avg       0.15      0.15      0.15       669

[[-0.7001025  -2.7972488  -2.3330586  -5.5241294  -5.801499    1.4195578
  -3.0152137 ]
 [-2.1982987  -3.8856387  -4.5456915  -6.4553475  -5.9452953  -0.24720658
  -1.1794487 ]
 [-5.817723   -4.956667   -4.348669   -6.730557   -6.276357   -1.6872939
   0.46082985]
 [-1.4377443  -2.2815418  -3.8805296  -6.131844   -5.8969326   0.99298227
  -2.7690744 ]
 [ 1.2653177   2.7340662   1.8210615  -2.0272896  -4.215947    4.336047
  -6.6271753 ]
 [-5.308517   -4.55602    -5.3135114  -8.0123415  -7.6158395  -2.301942
   0.86586154]
 [-4.8011003  -2.7465634  -3.2566037  -5.7069917  -4.393291    0.90983987
  -2.5529926 ]
 [-5.3978086  -3.1756997  -0.5621619  -6.1686063  -6.6918097   0.8555879
  -2.8517    ]
 [-5.735529   -3.3414493  -1.5069536  -5.94522    -6.0758753   0.5664735
  -2.1570816 ]
 [-4.3211937  -3.2128117  -5.3395886  -7.3780518  -7.0676274  -0.94874907
  -0.34937426]]
before change
[[0. 1. 1. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 1. 0.]
 [0. 1. 1. 1. 1. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0.]
 [1. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 1. 1. 0. 0. 1. 0.]
 [0. 1. 1. 0. 0. 1. 0.]
 [0. 1. 1. 0. 1. 1. 0.]
 [0. 0. 1. 0. 0. 1. 0.]
 [0. 1. 1. 1. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [1. 1. 0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0.]
 [0. 0. 1. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 1. 0.]
 [1. 1. 1. 1. 1. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 1. 1. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 1. 1. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 1. 0.]
 [0. 1. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 1. 0.]
 [0. 0. 1. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [1. 1. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [1. 1. 1. 0. 0. 1. 0.]
 [0. 1. 1. 0. 0. 1. 0.]
 [0. 1. 1. 0. 0. 1. 0.]]
[tensor([0.0423, 0.9345, 0.8119, 0.0686, 0.0327, 0.9845]), tensor([0.0344, 0.4329, 0.6584, 0.0669, 0.0141, 0.9747]), tensor([0.1148, 0.9286, 0.9521, 0.8034, 0.9913, 0.9955]), tensor([0.0396, 0.6422, 0.6438, 0.0633, 0.0165, 0.9769]), tensor([0.0082, 0.4338, 0.9345, 0.0882, 0.0500, 0.9851]), tensor([0.0056, 0.1236, 0.0692, 0.0053, 0.0055, 0.7792]), tensor([0.1164, 0.2340, 0.0755, 0.0541, 0.8344, 0.9625]), tensor([0.9179, 0.2784, 0.1318, 0.0186, 0.0481, 0.9377]), tensor([0.0011, 0.0017, 0.0035, 0.0002, 0.0005, 0.0181]), tensor([0.5594, 0.2463, 0.0688, 0.0363, 0.3362, 0.9551]), tensor([0.0455, 0.9738, 0.9900, 0.5533, 0.2357, 0.9966]), tensor([0.0560, 0.9202, 0.9719, 0.2042, 0.0052, 0.9892]), tensor([0.0508, 0.8678, 0.8967, 0.5000, 0.9678, 0.9929]), tensor([0.0197, 0.3290, 0.9063, 0.0911, 0.1038, 0.9847]), tensor([0.0996, 0.9581, 0.9960, 0.9870, 0.3458, 0.9969]), tensor([0.0002, 0.0003, 0.0006, 0.0002, 0.0001, 0.0008]), tensor([0.8397, 0.7220, 0.5994, 0.0629, 0.2809, 0.9850]), tensor([0.0293, 0.2801, 0.9446, 0.3428, 0.1272, 0.9892]), tensor([0.7691, 0.1791, 0.1202, 0.0082, 0.0140, 0.9086]), tensor([0.0083, 0.0273, 0.2490, 0.0103, 0.0356, 0.8417]), tensor([0.5469, 0.5940, 0.8480, 0.0645, 0.0344, 0.9890]), tensor([0.0845, 0.0854, 0.0215, 0.0150, 0.7446, 0.8529]), tensor([0.0089, 0.1227, 0.8037, 0.0193, 0.0151, 0.9485]), tensor([0.9365, 0.8505, 0.7212, 0.0796, 0.0149, 0.9790]), tensor([0.9930, 0.9869, 0.9884, 0.9293, 0.8931, 0.9980]), tensor([0.1005, 0.1062, 0.1216, 0.0437, 0.0688, 0.9443]), tensor([0.3606, 0.9492, 0.7080, 0.2548, 0.3872, 0.9928]), tensor([0.0514, 0.5463, 0.8699, 0.2339, 0.3703, 0.9902]), tensor([0.5600, 0.0677, 0.0379, 0.0075, 0.0315, 0.8522]), tensor([0.0014, 0.0064, 0.0797, 0.0004, 0.0003, 0.0929]), tensor([0.1277, 0.1606, 0.2246, 0.0370, 0.1230, 0.9709]), tensor([0.5860, 0.9186, 0.9837, 0.2366, 0.0114, 0.9923]), tensor([0.9144, 0.9162, 0.9438, 0.4688, 0.1449, 0.9952]), tensor([0.9951, 0.9361, 0.8666, 0.4238, 0.5145, 0.9914]), tensor([0.5957, 0.9439, 0.9933, 0.5739, 0.0217, 0.9962]), tensor([0.0004, 0.0007, 0.0015, 0.0001, 0.0002, 0.0039]), tensor([0.0683, 0.5117, 0.2568, 0.2050, 0.9856, 0.9742]), tensor([0.0070, 0.1141, 0.8831, 0.0245, 0.0091, 0.9507]), tensor([0.9863, 0.9636, 0.9515, 0.2733, 0.0262, 0.9859]), tensor([0.0407, 0.1768, 0.0313, 0.0260, 0.6750, 0.9282]), tensor([0.0006, 0.0022, 0.0108, 0.0002, 0.0003, 0.0213]), tensor([0.0211, 0.8708, 0.9634, 0.0717, 0.0039, 0.9824]), tensor([0.0363, 0.0966, 0.0693, 0.0800, 0.9747, 0.8962]), tensor([0.0118, 0.0669, 0.0775, 0.0152, 0.2925, 0.8764]), tensor([0.7187, 0.9133, 0.3064, 0.0286, 0.0133, 0.9721]), tensor([0.0788, 0.1369, 0.0795, 0.0484, 0.0290, 0.8443]), tensor([0.0007, 0.0015, 0.0024, 0.0002, 0.0003, 0.0099]), tensor([0.9873, 0.8370, 0.6577, 0.1320, 0.0771, 0.9842]), tensor([0.0932, 0.8268, 0.9223, 0.2321, 0.4540, 0.9932]), tensor([0.4721, 0.9262, 0.9018, 0.1370, 0.0129, 0.9913])]
[[0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0]]
[[0. 1. 1. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 1. 0.]
 [0. 1. 1. 1. 1. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0.]
 [1. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 1. 1. 0. 0. 1. 0.]
 [0. 1. 1. 0. 0. 1. 0.]
 [0. 1. 1. 0. 1. 1. 0.]
 [0. 0. 1. 0. 0. 1. 0.]
 [0. 1. 1. 1. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [1. 1. 0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0.]
 [0. 0. 1. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 1. 0.]
 [1. 1. 1. 1. 1. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 1. 1. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 1. 1. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 1. 0.]
 [0. 1. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 1. 0.]
 [0. 0. 1. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [1. 1. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1.]
 [1. 1. 1. 0. 0. 1. 0.]
 [0. 1. 1. 0. 0. 1. 0.]
 [0. 1. 1. 0. 0. 1. 0.]]
END: ma 6.2.2023 15.29.55 +0200
