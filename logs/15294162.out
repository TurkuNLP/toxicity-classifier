START ma 6.2.2023 11.35.46 +0200
Namespace(model='models/finbert-large-deepl', data='data/test_fi_deepl.jsonl', tokenizer='TurkuNLP/bert-base-finnish-cased-v1', filename='test2.tsv', new_test=True, threshold=0.5)
                                                text  ...              labels
0  Persujen mamu-puputus kyllästyttää  mutta mamu...  ...  [0, 0, 0, 0, 0, 1]
1  Suvakit ja hyysärit haluaa saada lapset omaan ...  ...  [0, 0, 0, 0, 0, 1]
2  VIELÄ YKSI ASIA! NÄMÄ EI OLE HENKILÖVAALIT,VAA...  ...  [0, 0, 0, 0, 0, 0]
3  Halosen aikana on lapsiin ja naisiin kohdistun...  ...  [0, 0, 0, 0, 0, 1]
4  Byää! Byää! Jos tulee vammoja, byää! Saatanan ...  ...  [0, 0, 0, 0, 0, 1]

[5 rows x 3 columns]
Dataset({
    features: ['text', 'id', 'labels'],
    num_rows: 2252
})
before change
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [1. 1. 1. 1. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]]
tensor([[1.1840e-01, 5.8340e-02, 1.4804e-01, 3.0689e-03, 5.7892e-03, 9.3099e-01],
        [8.5944e-02, 3.9587e-02, 1.2726e-01, 3.2833e-03, 1.2636e-02, 9.2524e-01],
        [1.3314e-03, 3.4000e-03, 7.9556e-03, 1.6218e-04, 1.7250e-03, 6.3318e-02],
        [4.3667e-02, 1.0461e-01, 1.8257e-01, 5.1093e-03, 8.1963e-03, 9.8091e-01],
        [9.9302e-01, 9.9851e-01, 9.9841e-01, 7.2457e-01, 5.2963e-02, 9.9922e-01],
        [3.0064e-04, 1.1481e-03, 2.7582e-03, 6.5535e-05, 4.8457e-04, 2.0657e-02],
        [1.1050e-02, 2.5606e-02, 1.0061e-01, 1.0591e-03, 4.6801e-03, 5.2831e-01],
        [3.4559e-03, 5.7862e-02, 9.5298e-01, 1.1666e-02, 4.2714e-03, 9.7839e-01],
        [8.4953e-03, 2.8285e-02, 1.0968e-01, 9.5429e-04, 3.1840e-03, 4.8982e-01],
        [7.8740e-04, 2.4626e-03, 5.4028e-03, 1.1414e-04, 1.1117e-03, 4.0459e-02]])
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 ...
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]]
tensor([[1.1840e-01, 5.8340e-02, 1.4804e-01, 3.0689e-03, 5.7892e-03, 9.3099e-01],
        [8.5944e-02, 3.9587e-02, 1.2726e-01, 3.2833e-03, 1.2636e-02, 9.2524e-01],
        [1.3314e-03, 3.4000e-03, 7.9556e-03, 1.6218e-04, 1.7250e-03, 6.3318e-02],
        [4.3667e-02, 1.0461e-01, 1.8257e-01, 5.1093e-03, 8.1963e-03, 9.8091e-01],
        [9.9302e-01, 9.9851e-01, 9.9841e-01, 7.2457e-01, 5.2963e-02, 9.9922e-01],
        [3.0064e-04, 1.1481e-03, 2.7582e-03, 6.5535e-05, 4.8457e-04, 2.0657e-02],
        [1.1050e-02, 2.5606e-02, 1.0061e-01, 1.0591e-03, 4.6801e-03, 5.2831e-01],
        [3.4559e-03, 5.7862e-02, 9.5298e-01, 1.1666e-02, 4.2714e-03, 9.7839e-01],
        [8.4953e-03, 2.8285e-02, 1.0968e-01, 9.5429e-04, 3.1840e-03, 4.8982e-01],
        [7.8740e-04, 2.4626e-03, 5.4028e-03, 1.1414e-04, 1.1117e-03, 4.0459e-02],
        [2.3153e-04, 7.6717e-04, 1.8308e-03, 6.4507e-05, 4.7652e-04, 1.2835e-02],
        [7.5299e-04, 2.2751e-03, 5.1159e-03, 1.1101e-04, 1.1013e-03, 3.8370e-02],
        [1.2145e-02, 1.0133e-01, 4.3918e-01, 4.7401e-03, 5.8265e-03, 9.6724e-01],
        [5.2549e-02, 9.9673e-01, 9.9422e-01, 5.4483e-02, 1.3416e-02, 9.9800e-01],
        [1.2601e-02, 1.2079e-01, 4.1746e-01, 5.2426e-03, 6.7586e-03, 9.7791e-01],
        [1.6833e-04, 4.7275e-04, 1.1108e-03, 7.4856e-05, 3.5607e-04, 7.4998e-03],
        [1.7595e-02, 5.4628e-02, 2.2218e-01, 2.6679e-03, 7.1091e-03, 8.8283e-01],
        [1.6769e-02, 5.5754e-02, 1.8045e-01, 3.0243e-03, 1.0789e-02, 9.4087e-01],
        [2.3110e-04, 7.6603e-04, 1.8333e-03, 6.4573e-05, 4.7791e-04, 1.2838e-02],
        [3.9925e-01, 6.5319e-01, 9.6449e-01, 1.8230e-02, 4.1518e-03, 9.9205e-01],
        [1.9103e-02, 2.8545e-02, 1.0896e-01, 1.3445e-03, 5.1196e-03, 6.1394e-01],
        [1.6990e-02, 6.3727e-02, 4.4615e-01, 8.4985e-03, 8.8691e-03, 9.8658e-01],
        [3.6052e-03, 7.8018e-03, 2.0645e-02, 3.5055e-04, 4.0958e-03, 1.8517e-01],
        [1.0782e-02, 2.4858e-02, 7.4568e-02, 8.6006e-04, 3.6202e-03, 4.7710e-01],
        [1.4044e-02, 5.9392e-02, 1.2804e-01, 1.2697e-03, 3.8775e-03, 7.3303e-01],
        [4.8016e-03, 1.3546e-02, 3.4415e-02, 4.4217e-04, 2.3949e-03, 2.3065e-01],
        [1.8502e-02, 8.4011e-02, 2.1282e-01, 3.0414e-03, 8.3536e-03, 9.4078e-01],
        [3.7046e-03, 4.9031e-01, 5.9418e-01, 2.9704e-03, 2.3252e-03, 9.7833e-01],
        [8.6604e-03, 5.4315e-02, 1.0441e-01, 7.5629e-04, 2.8981e-03, 6.5202e-01],
        [8.2812e-02, 7.9361e-01, 9.8650e-01, 2.1072e-02, 4.2896e-03, 9.9417e-01]])
[[0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]]
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]]
                       precision    recall  f1-score   support

label_identity_attack       1.00      0.32      0.49       131
         label_insult       1.00      0.48      0.64       141
        label_obscene       1.00      0.83      0.91       170
label_severe_toxicity       1.00      0.28      0.44        25
         label_threat       1.00      0.28      0.43        40
       label_toxicity       1.00      0.78      0.88       158

            micro avg       1.00      0.59      0.74       665
            macro avg       1.00      0.49      0.63       665
         weighted avg       1.00      0.59      0.71       665
          samples avg       0.17      0.17      0.17       665

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'eval_accuracy': 0.8783303730017762,
 'eval_f1': 0.740530303030303,
 'eval_f1_macro': 0.6301416171052614,
 'eval_hamming loss': 0.020278271166370633,
 'eval_loss': 1.3107070922851562,
 'eval_macro_roc_auc': 0.7465567307792957,
 'eval_micro_roc_auc': 0.793984962406015,
 'eval_precision': 1.0,
 'eval_probs_roc_auc': 0.7003364227113725,
 'eval_recall': 0.58796992481203,
 'eval_runtime': 76.0128,
 'eval_samples_per_second': 29.627,
 'eval_steps_per_second': 3.71}
before change
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [1. 1. 1. 1. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]]
tensor([[1.1840e-01, 5.8340e-02, 1.4804e-01, 3.0689e-03, 5.7892e-03, 9.3099e-01],
        [8.5944e-02, 3.9587e-02, 1.2726e-01, 3.2833e-03, 1.2636e-02, 9.2524e-01],
        [1.3314e-03, 3.4000e-03, 7.9556e-03, 1.6218e-04, 1.7250e-03, 6.3318e-02],
        [4.3667e-02, 1.0461e-01, 1.8257e-01, 5.1093e-03, 8.1963e-03, 9.8091e-01],
        [9.9302e-01, 9.9851e-01, 9.9841e-01, 7.2457e-01, 5.2963e-02, 9.9922e-01],
        [3.0064e-04, 1.1481e-03, 2.7582e-03, 6.5535e-05, 4.8457e-04, 2.0657e-02],
        [1.1050e-02, 2.5606e-02, 1.0061e-01, 1.0591e-03, 4.6801e-03, 5.2831e-01],
        [3.4559e-03, 5.7862e-02, 9.5298e-01, 1.1666e-02, 4.2714e-03, 9.7839e-01],
        [8.4953e-03, 2.8285e-02, 1.0968e-01, 9.5429e-04, 3.1840e-03, 4.8982e-01],
        [7.8740e-04, 2.4626e-03, 5.4028e-03, 1.1414e-04, 1.1117e-03, 4.0459e-02]])
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 ...
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]]
tensor([[1.1840e-01, 5.8340e-02, 1.4804e-01, 3.0689e-03, 5.7892e-03, 9.3099e-01],
        [8.5944e-02, 3.9587e-02, 1.2726e-01, 3.2833e-03, 1.2636e-02, 9.2524e-01],
        [1.3314e-03, 3.4000e-03, 7.9556e-03, 1.6218e-04, 1.7250e-03, 6.3318e-02],
        [4.3667e-02, 1.0461e-01, 1.8257e-01, 5.1093e-03, 8.1963e-03, 9.8091e-01],
        [9.9302e-01, 9.9851e-01, 9.9841e-01, 7.2457e-01, 5.2963e-02, 9.9922e-01],
        [3.0064e-04, 1.1481e-03, 2.7582e-03, 6.5535e-05, 4.8457e-04, 2.0657e-02],
        [1.1050e-02, 2.5606e-02, 1.0061e-01, 1.0591e-03, 4.6801e-03, 5.2831e-01],
        [3.4559e-03, 5.7862e-02, 9.5298e-01, 1.1666e-02, 4.2714e-03, 9.7839e-01],
        [8.4953e-03, 2.8285e-02, 1.0968e-01, 9.5429e-04, 3.1840e-03, 4.8982e-01],
        [7.8740e-04, 2.4626e-03, 5.4028e-03, 1.1414e-04, 1.1117e-03, 4.0459e-02],
        [2.3153e-04, 7.6717e-04, 1.8308e-03, 6.4507e-05, 4.7652e-04, 1.2835e-02],
        [7.5299e-04, 2.2751e-03, 5.1159e-03, 1.1101e-04, 1.1013e-03, 3.8370e-02],
        [1.2145e-02, 1.0133e-01, 4.3918e-01, 4.7401e-03, 5.8265e-03, 9.6724e-01],
        [5.2549e-02, 9.9673e-01, 9.9422e-01, 5.4483e-02, 1.3416e-02, 9.9800e-01],
        [1.2601e-02, 1.2079e-01, 4.1746e-01, 5.2426e-03, 6.7586e-03, 9.7791e-01],
        [1.6833e-04, 4.7275e-04, 1.1108e-03, 7.4856e-05, 3.5607e-04, 7.4998e-03],
        [1.7595e-02, 5.4628e-02, 2.2218e-01, 2.6679e-03, 7.1091e-03, 8.8283e-01],
        [1.6769e-02, 5.5754e-02, 1.8045e-01, 3.0243e-03, 1.0789e-02, 9.4087e-01],
        [2.3110e-04, 7.6603e-04, 1.8333e-03, 6.4573e-05, 4.7791e-04, 1.2838e-02],
        [3.9925e-01, 6.5319e-01, 9.6449e-01, 1.8230e-02, 4.1518e-03, 9.9205e-01],
        [1.9103e-02, 2.8545e-02, 1.0896e-01, 1.3445e-03, 5.1196e-03, 6.1394e-01],
        [1.6990e-02, 6.3727e-02, 4.4615e-01, 8.4985e-03, 8.8691e-03, 9.8658e-01],
        [3.6052e-03, 7.8018e-03, 2.0645e-02, 3.5055e-04, 4.0958e-03, 1.8517e-01],
        [1.0782e-02, 2.4858e-02, 7.4568e-02, 8.6006e-04, 3.6202e-03, 4.7710e-01],
        [1.4044e-02, 5.9392e-02, 1.2804e-01, 1.2697e-03, 3.8775e-03, 7.3303e-01],
        [4.8016e-03, 1.3546e-02, 3.4415e-02, 4.4217e-04, 2.3949e-03, 2.3065e-01],
        [1.8502e-02, 8.4011e-02, 2.1282e-01, 3.0414e-03, 8.3536e-03, 9.4078e-01],
        [3.7046e-03, 4.9031e-01, 5.9418e-01, 2.9704e-03, 2.3252e-03, 9.7833e-01],
        [8.6604e-03, 5.4315e-02, 1.0441e-01, 7.5629e-04, 2.8981e-03, 6.5202e-01],
        [8.2812e-02, 7.9361e-01, 9.8650e-01, 2.1072e-02, 4.2896e-03, 9.9417e-01]])
[[0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]]
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]]
                       precision    recall  f1-score   support

label_identity_attack       1.00      0.32      0.49       131
         label_insult       1.00      0.48      0.64       141
        label_obscene       1.00      0.83      0.91       170
label_severe_toxicity       1.00      0.28      0.44        25
         label_threat       1.00      0.28      0.43        40
       label_toxicity       1.00      0.78      0.88       158

            micro avg       1.00      0.59      0.74       665
            macro avg       1.00      0.49      0.63       665
         weighted avg       1.00      0.59      0.71       665
          samples avg       0.17      0.17      0.17       665

[[-2.0077057  -2.781364   -1.7500454  -5.7833786  -5.1459584   2.6019304 ]
 [-2.3641934  -3.1888514  -1.9253647  -5.715632   -4.3584876   2.5157344 ]
 [-6.620192   -5.6805673  -4.825888   -8.726649   -6.360818   -2.6941755 ]
 [-3.0865114  -2.147026   -1.4990041  -5.271564   -4.7958407   3.9392066 ]
 [ 4.958264    6.510385    6.4413867   0.9672206  -2.8837404   7.1610117 ]
 [-8.109295   -6.7684617  -5.8904324  -9.632868   -7.631772   -3.8588173 ]
 [-4.4942093  -3.638971   -2.1904821  -6.8492837  -5.35975     0.11336099]
 [-5.6642     -2.790094    3.0090714  -4.4393096  -5.451525    3.8125749 ]
 [-4.7597065  -3.5367484  -2.0940561  -6.953586   -5.74644    -0.04072533]
 [-7.1459813  -6.0040603  -5.2154245  -9.07795    -6.8007326  -3.1661634 ]]
before change
[[0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [1. 1. 1. 1. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 1. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 1. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 1. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 1. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 1. 1. 1. 0. 1.]]
tensor([[8.2566e-04, 2.5725e-03, 6.4730e-03, 1.1389e-04, 8.4557e-04, 4.3817e-02],
        [2.5007e-02, 5.5904e-02, 2.6403e-01, 2.8498e-03, 5.5744e-03, 8.8231e-01],
        [1.4030e-02, 9.3037e-01, 9.9744e-01, 1.1761e-01, 1.3892e-02, 9.9821e-01],
        [4.9041e-02, 9.9329e-01, 9.9894e-01, 2.7508e-01, 2.1362e-02, 9.9935e-01],
        [9.9188e-01, 9.9617e-01, 9.9912e-01, 9.9190e-01, 2.6965e-02, 9.9917e-01],
        [4.8314e-01, 9.9813e-01, 9.9725e-01, 2.7669e-01, 2.4388e-02, 9.9906e-01],
        [1.8022e-01, 9.9774e-01, 9.9948e-01, 9.9627e-01, 2.4982e-02, 9.9949e-01],
        [5.7359e-04, 1.8001e-03, 4.0679e-03, 9.1431e-05, 8.8781e-04, 2.9303e-02],
        [8.2161e-03, 9.7909e-01, 8.3644e-01, 7.2335e-03, 4.4332e-03, 9.9288e-01],
        [4.4618e-03, 4.9680e-02, 9.8062e-01, 1.8929e-02, 4.0566e-03, 9.8041e-01],
        [1.4320e-02, 3.5087e-02, 2.1732e-01, 3.2365e-03, 1.2198e-02, 8.5534e-01],
        [1.8885e-04, 4.5189e-04, 7.9358e-04, 1.0995e-04, 2.8520e-04, 3.4126e-03],
        [1.7929e-04, 4.3617e-04, 8.2481e-04, 1.0077e-04, 2.9078e-04, 4.0048e-03],
        [8.7443e-03, 4.8611e-01, 9.9556e-01, 8.3553e-02, 1.4883e-02, 9.9731e-01],
        [3.2607e-02, 9.9634e-01, 9.9830e-01, 1.9987e-01, 2.0756e-02, 9.9890e-01],
        [7.4389e-02, 9.9459e-01, 9.9853e-01, 2.9281e-01, 1.9000e-02, 9.9920e-01],
        [5.4568e-03, 7.9306e-02, 9.9035e-01, 3.5334e-02, 6.4689e-03, 9.9108e-01],
        [6.2744e-03, 3.8288e-01, 9.9436e-01, 5.6526e-02, 8.6914e-03, 9.9581e-01],
        [1.0757e-02, 9.8493e-01, 9.9649e-01, 4.4103e-02, 6.6789e-03, 9.9652e-01],
        [9.6688e-02, 9.9734e-01, 9.9963e-01, 9.6721e-01, 2.9848e-02, 9.9967e-01],
        [2.0581e-04, 4.7841e-04, 7.5019e-04, 1.3007e-04, 2.7395e-04, 2.6741e-03],
        [1.4779e-01, 9.9771e-01, 9.9956e-01, 9.9574e-01, 2.7781e-02, 9.9958e-01],
        [7.9419e-03, 9.8593e-02, 7.2795e-01, 6.3021e-03, 3.6672e-03, 9.7228e-01],
        [1.7193e-02, 8.5949e-02, 4.9562e-01, 3.6233e-02, 7.8332e-02, 9.9306e-01],
        [2.5574e-01, 9.9660e-01, 9.9826e-01, 2.3689e-01, 1.8103e-02, 9.9911e-01],
        [5.2437e-03, 4.4936e-01, 9.9717e-01, 1.1295e-01, 6.9390e-03, 9.9748e-01],
        [6.1846e-03, 2.1250e-01, 9.8480e-01, 2.6426e-02, 6.3262e-03, 9.9290e-01],
        [4.3868e-02, 9.8203e-01, 9.9848e-01, 2.3394e-01, 1.2412e-02, 9.9894e-01],
        [1.9114e-02, 9.9403e-01, 9.9713e-01, 5.9955e-02, 7.9121e-03, 9.9768e-01],
        [2.1433e-04, 7.1349e-04, 1.7101e-03, 6.4776e-05, 4.5961e-04, 1.2160e-02],
        [1.0696e-02, 9.8840e-01, 9.9763e-01, 9.3227e-02, 1.3485e-02, 9.9817e-01],
        [4.7539e-03, 4.0704e-01, 9.9264e-01, 4.6558e-02, 6.8443e-03, 9.9593e-01],
        [1.7784e-01, 9.9457e-01, 9.9741e-01, 1.4551e-01, 1.7490e-02, 9.9890e-01],
        [7.7896e-02, 8.3171e-01, 9.5491e-01, 2.9481e-02, 5.1841e-03, 9.9522e-01],
        [3.3650e-03, 1.2157e-02, 2.7992e-02, 3.4315e-04, 1.8836e-03, 1.9007e-01],
        [5.9230e-02, 9.9772e-01, 9.9819e-01, 2.3234e-01, 2.0540e-02, 9.9908e-01],
        [1.1428e-01, 9.9295e-01, 9.9263e-01, 1.1550e-01, 1.1461e-02, 9.9831e-01],
        [2.3718e-03, 5.4765e-03, 1.4603e-02, 2.5541e-04, 2.4361e-03, 1.1502e-01],
        [2.0045e-01, 9.9838e-01, 9.9939e-01, 9.7040e-01, 1.9573e-02, 9.9957e-01],
        [4.0905e-01, 9.9608e-01, 9.9772e-01, 1.8012e-01, 1.0580e-02, 9.9881e-01],
        [2.6001e-02, 9.9228e-01, 9.9677e-01, 6.0482e-02, 7.4631e-03, 9.9777e-01],
        [9.0158e-02, 9.9756e-01, 9.9749e-01, 2.0803e-01, 4.6752e-02, 9.9910e-01],
        [2.5246e-04, 8.4713e-04, 2.0181e-03, 6.4758e-05, 5.0627e-04, 1.3954e-02],
        [7.6755e-01, 4.7010e-02, 1.1504e-01, 8.8523e-03, 1.2075e-02, 9.7128e-01],
        [3.5881e-02, 9.9059e-01, 9.9779e-01, 1.0432e-01, 1.2901e-02, 9.9844e-01],
        [2.4267e-02, 6.9540e-02, 2.0873e-01, 3.6836e-03, 9.6868e-03, 9.7572e-01],
        [7.7626e-02, 9.9688e-01, 9.9892e-01, 2.9743e-01, 1.4008e-02, 9.9929e-01],
        [4.0095e-03, 1.6316e-01, 9.9274e-01, 3.7463e-02, 6.0846e-03, 9.9339e-01],
        [8.0037e-03, 1.3618e-01, 9.8355e-01, 4.4386e-02, 6.9922e-03, 9.9334e-01],
        [2.4043e-02, 9.9052e-01, 9.9934e-01, 6.5644e-01, 2.8944e-02, 9.9952e-01]])
[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]
[[0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]]
END: ma 6.2.2023 11.39.05 +0200
