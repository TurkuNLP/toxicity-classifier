START ma 6.2.2023 13.08.55 +0200
Namespace(model='models/finbert-large-deepl', data='data/test_fi_deepl.jsonl', tokenizer='TurkuNLP/bert-base-finnish-cased-v1', filename='test2.tsv', new_test=True, threshold=0.5)
                                                   text  ...              labels
0     Persujen mamu-puputus kyllästyttää  mutta mamu...  ...  [0, 0, 0, 0, 0, 1]
1     Suvakit ja hyysärit haluaa saada lapset omaan ...  ...  [0, 0, 0, 0, 0, 1]
2     VIELÄ YKSI ASIA! NÄMÄ EI OLE HENKILÖVAALIT,VAA...  ...  [0, 0, 0, 0, 0, 0]
3     Halosen aikana on lapsiin ja naisiin kohdistun...  ...  [0, 0, 0, 0, 0, 1]
4     Byää! Byää! Jos tulee vammoja, byää! Saatanan ...  ...  [0, 0, 0, 0, 0, 1]
...                                                 ...  ...                 ...
2255  Haista sinä vittu. Ryssähän se tänne on koko a...  ...  [0, 0, 0, 0, 0, 0]
2256  Äsen Ylen uutisissa: Lapin käräjäoikeus on hyl...  ...  [0, 0, 0, 0, 0, 0]
2257  mä en jaksa enää sitä haukkumista,perkele kun ...  ...  [0, 0, 0, 0, 0, 0]
2258  Ei ainakaan Chrome tyrkytä. Se aina kysyy että...  ...  [0, 0, 0, 0, 0, 0]
2259  Eihän noi ole ku paskapentuja 1 kaljan jälkeen...  ...  [0, 0, 0, 0, 1, 0]

[2260 rows x 3 columns]
Dataset({
    features: ['text', 'id', 'labels'],
    num_rows: 2260
})
before change
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [1. 1. 1. 1. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]]
tensor([[1.1840e-01, 5.8340e-02, 1.4804e-01, 3.0689e-03, 5.7892e-03, 9.3099e-01],
        [8.5944e-02, 3.9587e-02, 1.2726e-01, 3.2833e-03, 1.2636e-02, 9.2524e-01],
        [1.3314e-03, 3.4000e-03, 7.9556e-03, 1.6218e-04, 1.7250e-03, 6.3318e-02],
        [4.3667e-02, 1.0461e-01, 1.8257e-01, 5.1093e-03, 8.1963e-03, 9.8091e-01],
        [9.9302e-01, 9.9851e-01, 9.9841e-01, 7.2457e-01, 5.2963e-02, 9.9922e-01],
        [3.1383e-04, 1.2046e-03, 2.8696e-03, 6.5920e-05, 4.9445e-04, 2.1465e-02],
        [1.1050e-02, 2.5606e-02, 1.0061e-01, 1.0591e-03, 4.6801e-03, 5.2831e-01],
        [3.4559e-03, 5.7862e-02, 9.5298e-01, 1.1666e-02, 4.2714e-03, 9.7839e-01],
        [8.4953e-03, 2.8285e-02, 1.0968e-01, 9.5429e-04, 3.1840e-03, 4.8982e-01],
        [7.8740e-04, 2.4626e-03, 5.4028e-03, 1.1414e-04, 1.1117e-03, 4.0459e-02]])
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 ...
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 1. 0. 1.]]
tensor([[1.1840e-01, 5.8340e-02, 1.4804e-01, 3.0689e-03, 5.7892e-03, 9.3099e-01],
        [8.5944e-02, 3.9587e-02, 1.2726e-01, 3.2833e-03, 1.2636e-02, 9.2524e-01],
        [1.3314e-03, 3.4000e-03, 7.9556e-03, 1.6218e-04, 1.7250e-03, 6.3318e-02],
        [4.3667e-02, 1.0461e-01, 1.8257e-01, 5.1093e-03, 8.1963e-03, 9.8091e-01],
        [9.9302e-01, 9.9851e-01, 9.9841e-01, 7.2457e-01, 5.2963e-02, 9.9922e-01],
        [3.1383e-04, 1.2046e-03, 2.8696e-03, 6.5920e-05, 4.9445e-04, 2.1465e-02],
        [1.1050e-02, 2.5606e-02, 1.0061e-01, 1.0591e-03, 4.6801e-03, 5.2831e-01],
        [3.4559e-03, 5.7862e-02, 9.5298e-01, 1.1666e-02, 4.2714e-03, 9.7839e-01],
        [8.4953e-03, 2.8285e-02, 1.0968e-01, 9.5429e-04, 3.1840e-03, 4.8982e-01],
        [7.8740e-04, 2.4626e-03, 5.4028e-03, 1.1414e-04, 1.1117e-03, 4.0459e-02],
        [2.3153e-04, 7.6717e-04, 1.8308e-03, 6.4507e-05, 4.7652e-04, 1.2835e-02],
        [7.5299e-04, 2.2751e-03, 5.1159e-03, 1.1101e-04, 1.1013e-03, 3.8370e-02],
        [1.2145e-02, 1.0133e-01, 4.3918e-01, 4.7401e-03, 5.8265e-03, 9.6724e-01],
        [5.2549e-02, 9.9673e-01, 9.9422e-01, 5.4483e-02, 1.3416e-02, 9.9800e-01],
        [1.4627e-02, 1.0438e-01, 3.9655e-01, 5.0719e-03, 6.8583e-03, 9.7017e-01],
        [1.6833e-04, 4.7275e-04, 1.1108e-03, 7.4856e-05, 3.5607e-04, 7.4998e-03],
        [1.7595e-02, 5.4628e-02, 2.2218e-01, 2.6679e-03, 7.1091e-03, 8.8283e-01],
        [1.6769e-02, 5.5754e-02, 1.8045e-01, 3.0243e-03, 1.0789e-02, 9.4087e-01],
        [2.3110e-04, 7.6603e-04, 1.8333e-03, 6.4573e-05, 4.7791e-04, 1.2838e-02],
        [3.9925e-01, 6.5319e-01, 9.6449e-01, 1.8230e-02, 4.1518e-03, 9.9205e-01],
        [1.9103e-02, 2.8545e-02, 1.0896e-01, 1.3445e-03, 5.1196e-03, 6.1394e-01],
        [1.6990e-02, 6.3727e-02, 4.4615e-01, 8.4985e-03, 8.8691e-03, 9.8658e-01],
        [3.6052e-03, 7.8018e-03, 2.0645e-02, 3.5055e-04, 4.0958e-03, 1.8517e-01],
        [1.0782e-02, 2.4858e-02, 7.4568e-02, 8.6006e-04, 3.6202e-03, 4.7710e-01],
        [1.4044e-02, 5.9392e-02, 1.2804e-01, 1.2697e-03, 3.8775e-03, 7.3303e-01],
        [4.8016e-03, 1.3546e-02, 3.4415e-02, 4.4217e-04, 2.3949e-03, 2.3065e-01],
        [1.8502e-02, 8.4011e-02, 2.1282e-01, 3.0414e-03, 8.3536e-03, 9.4078e-01],
        [3.7046e-03, 4.9031e-01, 5.9418e-01, 2.9704e-03, 2.3252e-03, 9.7833e-01],
        [8.6604e-03, 5.4315e-02, 1.0441e-01, 7.5629e-04, 2.8981e-03, 6.5202e-01],
        [8.2812e-02, 7.9361e-01, 9.8650e-01, 2.1072e-02, 4.2896e-03, 9.9417e-01]])
[[0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]]
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]]
                       precision    recall  f1-score   support

label_identity_attack       0.23      0.32      0.27       131
         label_insult       0.12      0.46      0.19       145
        label_obscene       0.17      0.82      0.28       170
label_severe_toxicity       0.07      0.28      0.11        25
         label_threat       0.25      0.28      0.26        40
       label_toxicity       0.10      0.78      0.17       158

            micro avg       0.13      0.58      0.21       669
            macro avg       0.16      0.49      0.21       669
         weighted avg       0.15      0.58      0.23       669
          samples avg       0.17      0.17      0.17       669

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'eval_accuracy': 0.3668141592920354,
 'eval_f1': 0.21352313167259784,
 'eval_f1_macro': 0.21372088023657107,
 'eval_hamming loss': 0.2118731563421829,
 'eval_loss': 1.3078116178512573,
 'eval_macro_roc_auc': 0.6424717949027068,
 'eval_micro_roc_auc': 0.690866989970755,
 'eval_precision': 0.1306970509383378,
 'eval_probs_roc_auc': 0.6988538708752906,
 'eval_recall': 0.5829596412556054,
 'eval_runtime': 76.546,
 'eval_samples_per_second': 29.525,
 'eval_steps_per_second': 3.697}
before change
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [1. 1. 1. 1. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]]
tensor([[1.1840e-01, 5.8340e-02, 1.4804e-01, 3.0689e-03, 5.7892e-03, 9.3099e-01],
        [8.5944e-02, 3.9587e-02, 1.2726e-01, 3.2833e-03, 1.2636e-02, 9.2524e-01],
        [1.3314e-03, 3.4000e-03, 7.9556e-03, 1.6218e-04, 1.7250e-03, 6.3318e-02],
        [4.3667e-02, 1.0461e-01, 1.8257e-01, 5.1093e-03, 8.1963e-03, 9.8091e-01],
        [9.9302e-01, 9.9851e-01, 9.9841e-01, 7.2457e-01, 5.2963e-02, 9.9922e-01],
        [3.1383e-04, 1.2046e-03, 2.8696e-03, 6.5920e-05, 4.9445e-04, 2.1465e-02],
        [1.1050e-02, 2.5606e-02, 1.0061e-01, 1.0591e-03, 4.6801e-03, 5.2831e-01],
        [3.4559e-03, 5.7862e-02, 9.5298e-01, 1.1666e-02, 4.2714e-03, 9.7839e-01],
        [8.4953e-03, 2.8285e-02, 1.0968e-01, 9.5429e-04, 3.1840e-03, 4.8982e-01],
        [7.8740e-04, 2.4626e-03, 5.4028e-03, 1.1414e-04, 1.1117e-03, 4.0459e-02]])
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 ...
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 1. 0. 1.]]
tensor([[1.1840e-01, 5.8340e-02, 1.4804e-01, 3.0689e-03, 5.7892e-03, 9.3099e-01],
        [8.5944e-02, 3.9587e-02, 1.2726e-01, 3.2833e-03, 1.2636e-02, 9.2524e-01],
        [1.3314e-03, 3.4000e-03, 7.9556e-03, 1.6218e-04, 1.7250e-03, 6.3318e-02],
        [4.3667e-02, 1.0461e-01, 1.8257e-01, 5.1093e-03, 8.1963e-03, 9.8091e-01],
        [9.9302e-01, 9.9851e-01, 9.9841e-01, 7.2457e-01, 5.2963e-02, 9.9922e-01],
        [3.1383e-04, 1.2046e-03, 2.8696e-03, 6.5920e-05, 4.9445e-04, 2.1465e-02],
        [1.1050e-02, 2.5606e-02, 1.0061e-01, 1.0591e-03, 4.6801e-03, 5.2831e-01],
        [3.4559e-03, 5.7862e-02, 9.5298e-01, 1.1666e-02, 4.2714e-03, 9.7839e-01],
        [8.4953e-03, 2.8285e-02, 1.0968e-01, 9.5429e-04, 3.1840e-03, 4.8982e-01],
        [7.8740e-04, 2.4626e-03, 5.4028e-03, 1.1414e-04, 1.1117e-03, 4.0459e-02],
        [2.3153e-04, 7.6717e-04, 1.8308e-03, 6.4507e-05, 4.7652e-04, 1.2835e-02],
        [7.5299e-04, 2.2751e-03, 5.1159e-03, 1.1101e-04, 1.1013e-03, 3.8370e-02],
        [1.2145e-02, 1.0133e-01, 4.3918e-01, 4.7401e-03, 5.8265e-03, 9.6724e-01],
        [5.2549e-02, 9.9673e-01, 9.9422e-01, 5.4483e-02, 1.3416e-02, 9.9800e-01],
        [1.4627e-02, 1.0438e-01, 3.9655e-01, 5.0719e-03, 6.8583e-03, 9.7017e-01],
        [1.6833e-04, 4.7275e-04, 1.1108e-03, 7.4856e-05, 3.5607e-04, 7.4998e-03],
        [1.7595e-02, 5.4628e-02, 2.2218e-01, 2.6679e-03, 7.1091e-03, 8.8283e-01],
        [1.6769e-02, 5.5754e-02, 1.8045e-01, 3.0243e-03, 1.0789e-02, 9.4087e-01],
        [2.3110e-04, 7.6603e-04, 1.8333e-03, 6.4573e-05, 4.7791e-04, 1.2838e-02],
        [3.9925e-01, 6.5319e-01, 9.6449e-01, 1.8230e-02, 4.1518e-03, 9.9205e-01],
        [1.9103e-02, 2.8545e-02, 1.0896e-01, 1.3445e-03, 5.1196e-03, 6.1394e-01],
        [1.6990e-02, 6.3727e-02, 4.4615e-01, 8.4985e-03, 8.8691e-03, 9.8658e-01],
        [3.6052e-03, 7.8018e-03, 2.0645e-02, 3.5055e-04, 4.0958e-03, 1.8517e-01],
        [1.0782e-02, 2.4858e-02, 7.4568e-02, 8.6006e-04, 3.6202e-03, 4.7710e-01],
        [1.4044e-02, 5.9392e-02, 1.2804e-01, 1.2697e-03, 3.8775e-03, 7.3303e-01],
        [4.8016e-03, 1.3546e-02, 3.4415e-02, 4.4217e-04, 2.3949e-03, 2.3065e-01],
        [1.8502e-02, 8.4011e-02, 2.1282e-01, 3.0414e-03, 8.3536e-03, 9.4078e-01],
        [3.7046e-03, 4.9031e-01, 5.9418e-01, 2.9704e-03, 2.3252e-03, 9.7833e-01],
        [8.6604e-03, 5.4315e-02, 1.0441e-01, 7.5629e-04, 2.8981e-03, 6.5202e-01],
        [8.2812e-02, 7.9361e-01, 9.8650e-01, 2.1072e-02, 4.2896e-03, 9.9417e-01]])
[[0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]
 [0 0 0 0 0 1]]
[[0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]]
                       precision    recall  f1-score   support

label_identity_attack       0.23      0.32      0.27       131
         label_insult       0.12      0.46      0.19       145
        label_obscene       0.17      0.82      0.28       170
label_severe_toxicity       0.07      0.28      0.11        25
         label_threat       0.25      0.28      0.26        40
       label_toxicity       0.10      0.78      0.17       158

            micro avg       0.13      0.58      0.21       669
            macro avg       0.16      0.49      0.21       669
         weighted avg       0.15      0.58      0.23       669
          samples avg       0.17      0.17      0.17       669

[[-2.0077057  -2.781364   -1.7500454  -5.7833786  -5.1459584   2.6019304 ]
 [-2.3641934  -3.1888514  -1.9253647  -5.715632   -4.3584876   2.5157344 ]
 [-6.620192   -5.6805673  -4.825888   -8.726649   -6.360818   -2.6941755 ]
 [-3.0865114  -2.147026   -1.4990041  -5.271564   -4.7958407   3.9392066 ]
 [ 4.958264    6.510385    6.4413867   0.9672206  -2.8837404   7.1610117 ]
 [-8.06633    -6.720373   -5.8507123  -9.627004   -7.6115623  -3.8196423 ]
 [-4.4942093  -3.638971   -2.1904821  -6.8492837  -5.35975     0.11336099]
 [-5.6642     -2.790094    3.0090714  -4.4393096  -5.451525    3.8125749 ]
 [-4.7597065  -3.5367484  -2.0940561  -6.953586   -5.74644    -0.04072533]
 [-7.1459813  -6.0040603  -5.2154245  -9.07795    -6.8007326  -3.1661634 ]]
before change
[[0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 1. 1. 1.]
 [1. 0. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 1.]
 [1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 1. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 1. 1. 1. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [1. 1. 1. 1. 1. 1.]
 [0. 0. 1. 0. 0. 1.]
 [1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [1. 1. 1. 1. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [1. 1. 1. 0. 0. 1.]
 [1. 1. 1. 1. 0. 1.]
 [1. 1. 1. 0. 0. 1.]
 [1. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 1.]
 [0. 0. 1. 0. 0. 1.]
 [1. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [1. 1. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 1. 1.]]
tensor([[2.1498e-02, 9.8437e-01, 9.8825e-01, 3.6404e-02, 2.1226e-02, 9.9703e-01],
        [9.6773e-03, 7.6000e-01, 9.8859e-01, 3.8486e-02, 1.2297e-02, 9.9521e-01],
        [3.1908e-02, 9.9331e-01, 9.9514e-01, 8.6950e-01, 9.8950e-01, 9.9857e-01],
        [6.9902e-01, 4.4881e-01, 9.5929e-01, 3.8915e-02, 1.7286e-02, 9.9348e-01],
        [4.1406e-03, 9.5019e-01, 9.9793e-01, 1.8392e-01, 1.9246e-01, 9.9854e-01],
        [9.9370e-03, 8.8664e-01, 9.9389e-01, 4.8134e-02, 2.8742e-02, 9.9691e-01],
        [3.6634e-02, 8.9419e-02, 2.5574e-01, 3.4548e-01, 9.9933e-01, 9.8761e-01],
        [6.3669e-01, 3.1018e-02, 8.1555e-02, 6.0708e-03, 1.4395e-02, 9.4063e-01],
        [4.3684e-03, 1.0344e-02, 3.4058e-02, 4.6904e-04, 4.4361e-03, 2.5218e-01],
        [1.7650e-02, 1.0014e-01, 2.7704e-01, 5.7134e-03, 9.3371e-03, 9.7972e-01],
        [6.5595e-02, 9.9770e-01, 9.9874e-01, 6.4434e-01, 1.3526e-01, 9.9927e-01],
        [5.7441e-02, 9.9644e-01, 9.9733e-01, 1.2518e-01, 2.0003e-02, 9.9867e-01],
        [9.9486e-03, 9.8191e-01, 9.9776e-01, 1.2872e-01, 5.9904e-02, 9.9862e-01],
        [2.9392e-03, 1.2094e-01, 9.8870e-01, 3.9221e-02, 1.9214e-02, 9.9253e-01],
        [1.7528e-01, 9.9617e-01, 9.9949e-01, 9.9798e-01, 3.5800e-02, 9.9954e-01],
        [2.0084e-04, 4.6646e-04, 7.6933e-04, 1.2541e-04, 2.8880e-04, 2.9967e-03],
        [9.9954e-01, 9.8477e-01, 9.8471e-01, 6.8237e-01, 9.3077e-01, 9.9757e-01],
        [3.9769e-03, 1.0741e-01, 9.8836e-01, 2.6835e-02, 5.6294e-03, 9.9079e-01],
        [7.6755e-01, 4.7010e-02, 1.1504e-01, 8.8523e-03, 1.2075e-02, 9.7128e-01],
        [1.0537e-02, 2.7209e-02, 2.5756e-01, 4.6470e-03, 2.5979e-02, 8.9991e-01],
        [7.4217e-01, 2.4193e-01, 6.0818e-01, 1.2216e-02, 7.6131e-03, 9.8837e-01],
        [5.4153e-02, 5.0338e-02, 1.9880e-01, 2.4191e-01, 9.9904e-01, 9.8177e-01],
        [2.6461e-03, 5.1451e-02, 9.6291e-01, 1.3977e-02, 6.9443e-03, 9.7974e-01],
        [2.4338e-01, 9.5607e-01, 8.9775e-01, 1.5703e-02, 4.6240e-03, 9.9478e-01],
        [9.9874e-01, 9.9682e-01, 9.9861e-01, 9.0661e-01, 5.1822e-02, 9.9914e-01],
        [7.3654e-03, 6.9528e-02, 9.8190e-01, 2.4632e-02, 6.2259e-03, 9.8872e-01],
        [1.7594e-02, 1.4332e-01, 1.2377e-01, 3.4255e-03, 6.0199e-03, 9.8590e-01],
        [6.1032e-03, 7.1879e-02, 8.7062e-01, 1.5639e-02, 1.8050e-02, 9.8470e-01],
        [4.5376e-02, 3.5638e-02, 1.5851e-01, 5.1429e-03, 2.8551e-02, 9.6827e-01],
        [1.0226e-03, 3.0273e-03, 6.9776e-03, 1.3599e-04, 1.3136e-03, 5.2039e-02],
        [3.0918e-02, 4.5299e-02, 4.6334e-01, 8.5621e-03, 1.0353e-02, 9.8355e-01],
        [6.3480e-01, 9.6164e-01, 9.9555e-01, 9.3182e-02, 7.9657e-03, 9.9741e-01],
        [9.9795e-01, 9.9623e-01, 9.9716e-01, 6.0546e-01, 1.7762e-02, 9.9845e-01],
        [9.7283e-01, 9.9678e-01, 9.9438e-01, 1.9857e-01, 3.0483e-02, 9.9800e-01],
        [9.7955e-01, 9.7568e-01, 9.9812e-01, 4.8454e-01, 1.9253e-02, 9.9854e-01],
        [1.8719e-04, 4.4213e-04, 8.0445e-04, 1.0867e-04, 2.9037e-04, 3.6414e-03],
        [2.1441e-02, 7.3648e-02, 2.0178e-01, 2.2278e-01, 9.9869e-01, 9.8518e-01],
        [2.3015e-03, 1.4353e-01, 9.8995e-01, 6.2253e-02, 7.2516e-02, 9.9339e-01],
        [7.7729e-01, 9.5594e-01, 9.9314e-01, 6.2884e-02, 1.1484e-02, 9.9632e-01],
        [1.8646e-02, 3.9584e-02, 1.1121e-01, 2.8669e-03, 3.3597e-02, 9.5734e-01],
        [5.9426e-03, 6.1228e-02, 8.3128e-01, 5.1959e-03, 2.2506e-03, 9.3014e-01],
        [6.7633e-03, 8.4693e-01, 9.9418e-01, 3.3748e-02, 7.6286e-03, 9.9563e-01],
        [3.1945e-02, 6.8512e-02, 2.4551e-01, 3.4255e-01, 9.9947e-01, 9.8115e-01],
        [1.4740e-02, 6.3500e-02, 2.3242e-01, 3.1792e-03, 1.2229e-02, 9.2801e-01],
        [4.6282e-01, 9.9013e-01, 4.1217e-01, 7.8526e-03, 8.9581e-03, 9.9530e-01],
        [2.3706e-02, 4.4084e-02, 2.2669e-01, 2.7028e-03, 6.6288e-03, 8.3656e-01],
        [2.4178e-04, 8.0356e-04, 1.9199e-03, 6.4578e-05, 4.8828e-04, 1.3332e-02],
        [9.9558e-01, 5.3912e-01, 2.2878e-01, 2.0528e-02, 1.1347e-02, 9.8100e-01],
        [5.4056e-03, 7.6614e-01, 9.9602e-01, 3.8719e-02, 5.6322e-03, 9.9566e-01],
        [3.2710e-02, 8.7307e-01, 9.8749e-01, 2.1315e-01, 5.6949e-01, 9.9855e-01]])
[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0]]
[[0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 1. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 1. 1. 1. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 1.]
 [1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [1. 1. 1. 1. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [1. 1. 1. 0. 0. 1.]
 [1. 1. 1. 1. 0. 1.]
 [1. 1. 1. 0. 0. 1.]
 [1. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 1.]
 [1. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [1. 1. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0.]]
END: ma 6.2.2023 13.11.56 +0200
