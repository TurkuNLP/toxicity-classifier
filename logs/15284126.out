START Sun Feb  5 17:09:15 EET 2023
Namespace(model='models/finbert-large-deepl', data='data/test_fi_deepl.jsonl', tokenizer='TurkuNLP/bert-base-finnish-cased-v1', filename='test_predictions.tsv', new_test=False)
number of lines in the file 63978
                                                text  ...              labels
0  " \n\n Hei Pieter Pietersen, ja tervetuloa Wik...  ...  [0, 0, 0, 0, 0, 0]
1  " \n\n Sinut on väliaikaisesti estetty muokkaa...  ...  [0, 0, 0, 0, 0, 0]
2  {Tule!!!!! FUCK..... ok mies, olen todella tod...  ...  [0, 0, 1, 0, 0, 1]
3  " \n\n == Zeqin kieltäminen== \n Zeqin välimie...  ...  [0, 0, 0, 0, 0, 0]
4         . Tämä tili on Dantherocker1:n sukkanukke.  ...  [0, 0, 0, 0, 0, 0]

[5 rows x 3 columns]
Dataset({
    features: ['text', 'id', 'labels'],
    num_rows: 63978
})
Best threshold: 0.6499999999999999
[[0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 1 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]]
[[0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]]
                       precision    recall  f1-score   support

label_identity_attack       0.51      0.59      0.55       712
         label_insult       0.61      0.75      0.67      3427
        label_obscene       0.53      0.84      0.65      3691
label_severe_toxicity       0.25      0.71      0.37       367
         label_threat       0.51      0.55      0.53       211
       label_toxicity       0.54      0.85      0.66      6090

            micro avg       0.54      0.81      0.64     14498
            macro avg       0.49      0.72      0.57     14498
         weighted avg       0.54      0.81      0.65     14498
          samples avg       0.07      0.08      0.07     14498

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'eval_accuracy': 0.8710650536121792,
 'eval_f1': 0.6432094343261786,
 'eval_f1_macro': 0.5722186902582463,
 'eval_hamming loss': 0.033732949868183856,
 'eval_loss': 0.13864701986312866,
 'eval_macro_roc_auc': 0.8436356836049105,
 'eval_micro_roc_auc': 0.8888352191718445,
 'eval_precision': 0.5355356733195688,
 'eval_probs_roc_auc': 0.9716165930560444,
 'eval_recall': 0.805076562284453,
 'eval_runtime': 2050.1632,
 'eval_samples_per_second': 31.206,
 'eval_steps_per_second': 3.901}
Best threshold: 0.6499999999999999
[[0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 1 0 0 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]]
[[0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0.]]
                       precision    recall  f1-score   support

label_identity_attack       0.51      0.59      0.55       712
         label_insult       0.61      0.75      0.67      3427
        label_obscene       0.53      0.84      0.65      3691
label_severe_toxicity       0.25      0.71      0.37       367
         label_threat       0.51      0.55      0.53       211
       label_toxicity       0.54      0.85      0.66      6090

            micro avg       0.54      0.81      0.64     14498
            macro avg       0.49      0.72      0.57     14498
         weighted avg       0.54      0.81      0.65     14498
          samples avg       0.07      0.08      0.07     14498

[[0.00021147420920897275, 0.0004898225888609886, 0.0007501727668568492, 0.00013559809303842485, 0.00027423520805314183, 0.0025748766493052244], [0.00020941512775607407, 0.0004863541107624769, 0.0007511255680583417, 0.0001346258941339329, 0.00027755898190662265, 0.0026260216254740953], [0.042731381952762604, 0.9955374002456665, 0.9989013671875, 0.26176580786705017, 0.023023108020424843, 0.9992423057556152], [0.00021292042220011353, 0.0004985700943507254, 0.0007532734889537096, 0.00014141068095341325, 0.0002676989242900163, 0.0024642879143357277], [0.00287836161442101, 0.006715220399200916, 0.017328061163425446, 0.00028919559554196894, 0.0027016145177185535, 0.14285938441753387], [0.00020577438408508897, 0.00047582093975506723, 0.0007526353001594543, 0.00012838236580137163, 0.00027826352743431926, 0.002762969583272934], [0.00018655098392628133, 0.00044500562944449484, 0.0008025668212212622, 0.00010716423275880516, 0.0002874451456591487, 0.003612213535234332], [0.007017830386757851, 0.0375933013856411, 0.11414268612861633, 0.0007913694134913385, 0.0024750023148953915, 0.5314564108848572], [0.0002110170025844127, 0.0004920594510622323, 0.0007493496523238719, 0.0001369373349007219, 0.00027629538089968264, 0.0025551149155944586], [0.0002115149691235274, 0.000492891063913703, 0.0007495956961065531, 0.00013779567962046713, 0.0002742493525147438, 0.0025393276009708643]]
END: Sun Feb  5 18:18:49 EET 2023
