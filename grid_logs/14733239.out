START 14733239: Thu Dec 22 14:53:25 EET 2022
Namespace(train=['data/train_fi_deepl.jsonl'], test='data/test_fi_deepl.jsonl', model='TurkuNLP/bert-base-finnish-cased-v1', batch=4, epochs=10, learning=5e-05, threshold=None, loss=True, dev=True, clean_as_label=True, binary=False, save=None)
['data/train_fi_deepl.jsonl']
text      object
labels    object
dtype: object
text      object
labels    object
dtype: object
tensor([ 9.5238,  2.8571,  2.8571, 14.2857, 28.5714,  1.5873,  0.1579],
       device='cuda:0')
DatasetDict({
    train: Dataset({
        features: ['text', 'labels'],
        num_rows: 160
    })
    dev: Dataset({
        features: ['text', 'labels'],
        num_rows: 40
    })
    test: Dataset({
        features: ['text', 'labels'],
        num_rows: 200
    })
})
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'train_runtime': 44.3542, 'train_samples_per_second': 36.073, 'train_steps_per_second': 9.018, 'train_loss': 0.12535107612609864, 'epoch': 10.0}
Best threshold: 0.49999999999999994
                       precision    recall  f1-score   support

label_identity_attack       0.00      0.00      0.00         4
         label_insult       0.71      0.36      0.48        14
        label_obscene       0.80      0.29      0.42        14
label_severe_toxicity       0.00      0.00      0.00         2
         label_threat       0.00      0.00      0.00         0
       label_toxicity       0.42      0.38      0.40        21

            micro avg       0.50      0.31      0.38        55
            macro avg       0.32      0.17      0.22        55
         weighted avg       0.55      0.31      0.38        55
          samples avg       0.04      0.03      0.03        55

huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'epoch': 10.0,
 'eval_accuracy': 0.85,
 'eval_f1': 0.38202247191011235,
 'eval_f1_macro': 0.21620718462823726,
 'eval_hamming loss': 0.04583333333333333,
 'eval_loss': 0.4897688925266266,
 'eval_precision': 0.5,
 'eval_recall': 0.3090909090909091,
 'eval_roc_auc': 0.6471218737594283,
 'eval_runtime': 1.5005,
 'eval_samples_per_second': 133.292,
 'eval_steps_per_second': 8.664}
F1: 0.38202247191011235
Best threshold: 0.49999999999999994
                       precision    recall  f1-score   support

label_identity_attack       0.00      0.00      0.00         4
         label_insult       0.71      0.36      0.48        14
        label_obscene       0.80      0.29      0.42        14
label_severe_toxicity       0.00      0.00      0.00         2
         label_threat       0.00      0.00      0.00         0
       label_toxicity       0.42      0.38      0.40        21

            micro avg       0.50      0.31      0.38        55
            macro avg       0.32      0.17      0.22        55
         weighted avg       0.55      0.31      0.38        55
          samples avg       0.04      0.03      0.03        55

Best threshold: 0.3
                       precision    recall  f1-score   support

label_identity_attack       0.00      0.00      0.00         4
         label_insult       0.67      0.43      0.52        14
        label_obscene       0.44      0.29      0.35        14
label_severe_toxicity       0.00      0.00      0.00         2
         label_threat       0.00      0.00      0.00         0
       label_toxicity       0.38      0.38      0.38        21

            micro avg       0.42      0.33      0.37        55
            macro avg       0.25      0.18      0.21        55
         weighted avg       0.43      0.33      0.37        55
          samples avg       0.03      0.04      0.03        55

{0: 'label_identity_attack', 1: 'label_insult', 2: 'label_obscene', 3: 'label_severe_toxicity', 4: 'label_threat', 5: 'label_toxicity'}
200 200 200
Job ID: 14733239
Cluster: puhti
User/Group: annieske/annieske
State: RUNNING
Cores: 1
CPU Utilized: 00:01:15
CPU Efficiency: 60.98% of 00:02:03 core-walltime
Job Wall-clock time: 00:02:03
Memory Utilized: 3.48 GB
Memory Efficiency: 44.50% of 7.81 GB
Job consumed 2.11 CSC billing units based on following used resources
Billed project: project_2000539
CPU BU: 0.03
Mem BU: 0.03
GPU BU: 2.05
GPU job efficiency:
------------------------------------------------------------------------
Host memory 
     Hostname    Mean (GiB)  stdDev (GiB)     Max (GiB) 
       r02g01          4.37          3.44          8.22 
------------------------------------------------------------------------
GPU load 
     Hostname        GPU Id      Mean (%)    stdDev (%)       Max (%) 
       r02g01             2 [31m         23.5 [0m        42.52            95 
------------------------------------------------------------------------
GPU memory 
     Hostname        GPU Id    Mean (GiB)  stdDev (GiB)     Max (GiB) 
       r02g01             2          2.37          2.75           6.3 
------------------------------------------------------------------------
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
END 14733239: Thu Dec 22 14:55:22 EET 2022
